{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://www.verifia.ca/assets/logo.png\" width=\"160px\" alt=\"VerifIA Logo\"/><br>\n",
    "  <strong>© 2025 VerifIA. All rights reserved.</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install verifia[genflow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VerifIA - Rule-Based Verification Quickstart\n",
    "\n",
    "This notebook demonstrates two approaches for generating a domain configuration for model verification using the California housing dataset. You can either manually create a simple domain dictionary based on your intuition or use VerifIA’s AI-powered generation flow to create a domain file automatically from the dataframe and descriptive domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries and Setting Up\n",
    "\n",
    "In this section, we import the required Python libraries and modules. These include standard data science package, scikit-learn, and the specific modules from the VerifIA tool that handle model wrapping and rule verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from verifia.models import SKLearnModel, build_from_model_card\n",
    "from verifia.verification.results import RulesViolationResult\n",
    "from verifia.verification.verifiers import RuleConsistencyVerifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setting Constants and Directories\n",
    "\n",
    "We define some key constants such as the random seed for reproducibility and the directory path where our model artifacts will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_SEED = 0\n",
    "MODELS_DIRPATH = \"../models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Loading the California Housing Data\n",
    "\n",
    "Using scikit-learn’s `fetch_california_housing`, we load the California housing dataset into a DataFrame. We extract the feature names and target name directly from the dataset, which will be used later for model training and verification. The dataset is split into training and testing subsets (80/20 split) to allow for model training on one set and evaluation/verification on the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing(as_frame=True)\n",
    "housing_df = housing.frame\n",
    "feature_names = housing.feature_names\n",
    "target_name = housing.target_names[0]\n",
    "train_df, test_df = train_test_split(housing_df, train_size=0.8, random_state=RAND_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training Multiple Regression Models\n",
    "\n",
    "We create and train several regression models using different pipelines:\n",
    "- **Polynomial Regression:** A pipeline with standard scaling, polynomial feature expansion (degree 2), and linear regression.\n",
    "- **Decision Tree Regressor:** A simple decision tree model with standard scaling.\n",
    "- **Random Forest Regressor:** An ensemble model using random forests.\n",
    "- **MLP Regressor:** A multi-layer perceptron with a specific hidden layer configuration.\n",
    "\n",
    "Each model is trained on the training data, and key performance metrics (RMSE and MAPE) are computed on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Optional: Run this cell to train the polynomial regression model\n",
    "This cell trains a polynomial regression model using a 2nd degree polynomial expansion. The model is scaled with StandardScaler and fit using LinearRegression, which helps capture non-linear relationships in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2), LinearRegression())\n",
    "poly_reg.fit(train_df[feature_names], train_df[target_name])\n",
    "poly_predictions = poly_reg.predict(test_df[feature_names])\n",
    "poly_rmse = root_mean_squared_error(test_df[target_name], poly_predictions)\n",
    "poly_mape = mean_absolute_percentage_error(test_df[target_name], poly_predictions)\n",
    "print(poly_rmse, poly_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Optional: Run this cell to train the decision tree regression model\n",
    "This cell trains a decision tree regressor using StandardScaler and DecisionTreeRegressor. Decision trees are useful for capturing non-linear patterns without requiring explicit feature engineering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = make_pipeline(StandardScaler(), DecisionTreeRegressor(random_state=RAND_SEED))\n",
    "tree_reg.fit(train_df[feature_names], train_df[target_name])\n",
    "tree_predictions = tree_reg.predict(test_df[feature_names])\n",
    "tree_rmse = root_mean_squared_error(test_df[target_name], tree_predictions)\n",
    "tree_mape = mean_absolute_percentage_error(test_df[target_name], tree_predictions)\n",
    "print(tree_rmse, tree_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3 Optional: Run this cell to train the random forest regression model\n",
    "This cell trains a random forest model, which aggregates multiple decision trees to improve robustness and accuracy. It uses StandardScaler along with RandomForestRegressor to capture ensemble learning benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=RAND_SEED))\n",
    "forest_reg.fit(train_df[feature_names], train_df[target_name])\n",
    "forest_predictions = forest_reg.predict(test_df[feature_names])\n",
    "forest_rmse = root_mean_squared_error(test_df[target_name], forest_predictions)\n",
    "forest_mape = mean_absolute_percentage_error(test_df[target_name], forest_predictions)\n",
    "print(forest_rmse, forest_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4 Optional: Run this cell to train the neural network regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = make_pipeline(StandardScaler(), \n",
    "                        MLPRegressor(hidden_layer_sizes=(128,64,32), activation='relu', solver='adam', random_state=RAND_SEED))\n",
    "mlp_reg.fit(train_df[feature_names], train_df[target_name])\n",
    "test_predictions = mlp_reg.predict(test_df[feature_names])\n",
    "mlp_rmse = root_mean_squared_error(test_df[target_name], test_predictions)\n",
    "mlp_mape = mean_absolute_percentage_error(test_df[target_name], test_predictions)\n",
    "print(mlp_rmse, poly_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Wrapping the Model with VerifIA\n",
    "\n",
    "VerifIA requires that the model is wrapped in a standardized model wrapper. Here, we use the `build_from_model_card` function to create a `SKLearnModel` instance that encapsulates essential metadata (such as model name, version, type, feature names, target name, and storage directory) along with the trained model. \n",
    "\n",
    "**Note:** You can swap out the pipeline (e.g., use tree, forest, or mlp regressors) by adjusting the wrapper configuration and replacing the wrapped model object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper:SKLearnModel = build_from_model_card({\n",
    "    \"name\": \"CHPrice_skl_poly_regressor\", # instead of \"poly\", you should put \"tree\", \"forest\", \"mlp\"\n",
    "    \"version\": \"1\",\n",
    "    \"type\": \"regression\",\n",
    "    \"description\": \"model predicts the prices of california houses\",\n",
    "    \"framework\": \"sklearn\",\n",
    "    \"feature_names\": feature_names,\n",
    "    \"target_name\": target_name,\n",
    "    \"local_dirpath\": MODELS_DIRPATH\n",
    "}).wrap_model(poly_reg) # instead of poly_reg, you should put tree_reg, forest_reg, mlp_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Creating the Domain Configuration\n",
    "\n",
    "We present two options for creating the domain configuration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Option A – Manual Domain Dictionary**\n",
    "\n",
    "You can manually create a simple domain dictionary. In this example, a dictionary is built where each variable is defined based on the features from the California housing dataframe. A sample constraint (e.g., a ratio between average bedrooms and rooms) and a rule (R1) are included. You can further customize and extend this dictionary with additional rules as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_cfg_dict = {\n",
    "    \"variables\":{\n",
    "        col: {\n",
    "            \"type\": \"INT\" if (is_int := (housing_df[col] == housing_df[col].round()).all()) else \"FLOAT\",\n",
    "            \"range\": (housing_df[col].astype(int) if is_int else housing_df[col]).agg(['min', 'max']).tolist()\n",
    "        }\n",
    "        for col in housing_df.columns\n",
    "    },\n",
    "    \"constraints\":{\n",
    "        \"C1\": {\n",
    "                \"description\":\"\", \n",
    "                \"formula\": \"AveBedrms/AveRooms > 0.5\"\n",
    "            }\n",
    "    },\n",
    "    \"rules\":{\n",
    "        \"R1\": {\n",
    "               \"description\": \"\",\n",
    "               \"premises\": {\"AveRooms\":\"inc\", \"AveBedrms\":\"inc\", \"HouseAge\": \"dec\"},\n",
    "               \"conclusion\": {\"MedHouseVal\":\"inc\"}\n",
    "            }\n",
    "    }\n",
    "}\n",
    "domain_cfg_dict[\"variables\"]['MedHouseVal']['insignificant_variation'] = 0.15 # expect 15% of error as acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Option B – AI-Powered Domain Generation**\n",
    "Alternatively, you can leverage VerifIA’s `DomainGenFlow` to generate a domain dictionary automatically. By providing the dataframe and a description (here, the dataset’s description from `housing.DESCR`), the tool generates a domain configuration using AI. Additionally, you can customize the GPT configuration for domain dictionary generation by setting the environment variables `VERIFIA_GPT_NAME` and `VERIFIA_GPT_TEMPERATURE`. The defaults for these variables are: `VERIFIA_GPT_NAME` is set to \"gpt-4o-mini\" and `VERIFIA_GPT_TEMPERATURE` is set to 0. You can include them in a `.env` file along with your `OPEN_API_KEY` if you want to change the default options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup OpenAI and LangSmith Keys**\n",
    "\n",
    "Note that LangSmith is not needed, but it is helpful. If you do want to use LangSmith, after you sign up at the link above, make sure to set your environment variables to start logging traces.\n",
    "\n",
    "Accessing the OpenAI API requires an API key, which you can get by creating an account. Once you have a key you'll want to set it as an environment variable by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(prompt='Your LANGCHAIN_API_KEY? ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt='Your OPENAI_API_KEY? ')\n",
    "os.environ[\"USER_AGENT\"] = 'my_agent'\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = 'VERIFIA_TEST'\n",
    "os.environ[\"VERIFIA_GPT_NAME\"] = 'gpt-4.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verifia.generation import DomainGenFlow\n",
    "\n",
    "domain_genflow = DomainGenFlow()\n",
    "domain_genflow.load_ctx(dataframe=housing_df, \n",
    "                        db_str_content=str(housing.DESCR),\n",
    "                        model_card=model_wrapper.model_card.to_dict())\n",
    "domain_cfg_dict = domain_genflow.run(save=True, local_path=\"./domain.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Instantiating the Rule Consistency Verifier\n",
    "\n",
    "Using the constructed or generated domain configuration, we instantiate a `RuleConsistencyVerifier`. This component is responsible for checking the consistency of the model with respect to the defined rules and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_verifier = RuleConsistencyVerifier(domain_cfg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Configuring and Running the Verification\n",
    "\n",
    "Next, we connect the verifier to our wrapped model and the test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_verifier.verify(model_wrapper).on(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we choose to run the verification using a Genetic Algorithm (GA) as the search strategy. We specify parameters such as:\n",
    "- **Population Size:** 50\n",
    "- **Maximum Iterations:** 10\n",
    "- **Original Seed Size:** 100\n",
    "\n",
    "The verifier explores the input space to identify any rule violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result:RulesViolationResult = model_verifier.using(\"RS\")\\\n",
    "                                            .run(pop_size=50, max_iters=10, \n",
    "                                                 orig_seed_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Saving the Results and Model Artifacts\n",
    "\n",
    "Finally, the verification results are saved as an HTML report, which provides a comprehensive summary of the rule evaluations and any detected inconsistencies. Additionally, the model and its model card are saved for future reference and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save_as_html(\"../reports/CHPrice_skl_poly_regressor.html\")  \n",
    "# \"poly\" is used for the polynomial model, \n",
    "# ensure that the report's filename includes a short identifier reflecting the specific model used. \n",
    "# For instance, use \"tree\" for a decision tree model, \"forest\" for a random forest model, and \"mlp\" for a multi-layer perceptron. \n",
    "# This naming convention makes it easier to quickly identify which model generated the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.save_model()\n",
    "model_wrapper.save_model_card(\"../models/CHPrice_skl_poly_regressor.yaml\")\n",
    "# \"poly\" is used for the polynomial model, \n",
    "# ensure that the model card's filename includes a short identifier reflecting the specific model used. \n",
    "# For instance, use \"tree\" for a decision tree model, \"forest\" for a random forest model, and \"mlp\" for a multi-layer perceptron. \n",
    "# This naming convention makes it easier to quickly identify which model is described by the card."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
