{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://www.verifia.ca/assets/logo.png\" width=\"160px\" alt=\"VerifIA Logo\"/><br>\n",
    "  <strong>© 2025 VerifIA. All rights reserved.</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VerifIA - Model Verification: Hotel Cancellation Prediction with Scikit-Learn\n",
    "\n",
    "In this notebook we address a hotel cancellation prediction problem. We use a dataset of hotel bookings and build classification pipelines (using models such as SVC and Random Forest). The notebook demonstrates how to tune model hyperparameters, wrap the best model with VerifIA’s standardized interface, and then verify its rule consistency against a domain configuration—either generated automatically using AI-powered domain generation or loaded from a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install scikit-optimize\n",
    "!pip install \"../../dist/verifia-0.1.0-py3-none-any.whl[genflow]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Download Resources\n",
    "\n",
    "Before running any other cells, make sure you have all required resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -sL https://tinyurl.com/r6m2zk87 -o downloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extracted': True,\n",
       " 'files': ['articles/',\n",
       "  'articles/End-to-End Hotel Booking Cancellation Machine Learning Model.pdf',\n",
       "  'articles/eXplainable predictions for booking cancellation.pdf',\n",
       "  'articles/Hotel Booking Cancellation Prediction Using Applied Bayesian Models.pdf',\n",
       "  'articles/hotel booking cancellation prediction.pdf',\n",
       "  'articles/hotel booking demand datasets.pdf',\n",
       "  'articles/Modeling and Forecasting Hotel Booking Cancellations.pdf',\n",
       "  'data_report.pdf',\n",
       "  'domain_definition_meeting_notes.pdf',\n",
       "  'domain_definition_report.pdf',\n",
       "  'feature_selection_report.pdf',\n",
       "  'sensitivity_analysis_meeting_notes.pdf',\n",
       "  'sensitivity_analysis_report.pdf']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from downloader import download_resource\n",
    "url = 'https://www.verifia.ca/assets/use-cases/'\n",
    "download_resource(url+'data/hotel_cancellation.csv', \n",
    "                  dest_dir='../data')\n",
    "download_resource(url+'domains/hotel_cancellation.yaml', \n",
    "                  dest_dir='../domains')\n",
    "download_resource(url+'documents/hotel_cancellation.zip', \n",
    "                  dest_dir='../documents/hotel_cancellation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries and Setting Up\n",
    "\n",
    "First, we import necessary libraries for data processing (Pandas, NumPy), model building (scikit-learn), hyperparameter tuning (skopt’s BayesSearchCV and RandomizedSearchCV), and VerifIA modules (for model wrapping, verification, and domain generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import getpass\n",
    "import pandas as pd\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "from scipy.stats import loguniform\n",
    "from sklearn import svm\n",
    "from verifia.models import SKLearnModel, build_from_model_card\n",
    "from verifia.verification.results import RulesViolationResult\n",
    "from verifia.context.data import Dataset\n",
    "from verifia.verification.verifiers import RuleConsistencyVerifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Defining Constants and Loading the Data\n",
    "\n",
    "Key constants are defined, including a random seed for reproducibility, model directory paths, and the data file path. The hotel cancellation dataset is then loaded from a CSV file, and the target variable (*is_canceled*) is separated from the feature columns. Categorical features are identified from the dataset based on data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_SEED = 0\n",
    "MODELS_DIRPATH = \"../models\"\n",
    "DATA_PATH = \"../data/hotel_cancellation.csv\"\n",
    "dataframe = pd.read_csv(DATA_PATH)\n",
    "target_name = \"is_canceled\"\n",
    "feature_names = set(dataframe.columns) - {target_name}\n",
    "cat_feature_names = set(dataframe.select_dtypes(include=[\"object\"]).columns) - {target_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Building the Model Wrapper\n",
    "\n",
    "Using the `build_from_model_card` function from VerifIA, we create a `SKLearnModel` wrapper. This wrapper encapsulates essential metadata such as the model’s name, version, type (classification), feature names, target name, and local directory. The wrapper serves as a standardized interface between your model and the VerifIA verification framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper:SKLearnModel = build_from_model_card({\n",
    "    \"name\": \"hotel_cancellation\",\n",
    "    \"version\": \"2\",\n",
    "    \"type\": \"classification\",\n",
    "    \"description\": \"model predicts the hotel cancellations.\",\n",
    "    \"framework\": \"sklearn\",\n",
    "    \"feature_names\": feature_names,\n",
    "    \"cat_feature_names\": cat_feature_names,\n",
    "    \"target_name\": target_name,\n",
    "    \"local_dirpath\": MODELS_DIRPATH\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Preparing the Dataset\n",
    "\n",
    "The dataset is transformed into a VerifIA `Dataset` object. This object ensures that the data is properly formatted for model training, evaluation, and subsequent rule verification. The dataset is then split into training and testing subsets (80/20 split) to allow for both hyperparameter tuning and final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dataframe, model_wrapper.target_name, \n",
    "                  model_wrapper.feature_names, \n",
    "                  model_wrapper.cat_feature_names)\n",
    "train_dataset, test_dataset = dataset.split(0.8, RAND_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Creating Classification Pipelines\n",
    "\n",
    "Two types of pipelines are constructed:\n",
    "\n",
    "- **SVC Pipeline:**  \n",
    "  A pipeline is built using a `ColumnTransformer` that scales numerical features (using RobustScaler) and one-hot encodes categorical features. An SVC classifier (with probability estimates enabled) is then added to the pipeline.\n",
    "\n",
    "- **Random Forest Pipeline:**  \n",
    "  Another pipeline is created with the same preprocessing steps followed by a RandomForestClassifier (or alternatively, a GradientBoostingClassifier).  \n",
    "\n",
    "Hyperparameter tuning is set up for each model using different search strategies:\n",
    "- For SVC, a randomized search is performed over parameters such as kernel type, regularization (C), and gamma.\n",
    "- For Random Forest, a Bayesian search is defined over various hyperparameters (e.g., number of estimators, max depth, minimum samples split, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", RobustScaler(), train_dataset.num_feature_idxs),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), train_dataset.cat_feature_idxs)\n",
    "])\n",
    "\n",
    "svc = svm.SVC(probability=True, random_state=RAND_SEED)\n",
    "    \n",
    "svc_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('predictor', svc) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits_count, max_trials = 2, 1\n",
    "search_dict = {'predictor__kernel': ['linear', 'rbf'], \n",
    "               'predictor__C': loguniform(1, 1000),\n",
    "               'predictor__gamma': loguniform(0.0001, 0.1)}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cv_splits_count, shuffle=True, random_state=RAND_SEED)\n",
    "search_func = RandomizedSearchCV(estimator=svc_pipeline,\n",
    "                                param_distributions=search_dict,\n",
    "                                n_iter=max_trials,\n",
    "                                scoring=\"f1\",\n",
    "                                cv=skf,\n",
    "                                verbose=10,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X = train_dataset.feature_data()\n",
    "y = train_dataset.target_data\n",
    "svc_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", RobustScaler(), train_dataset.num_feature_idxs),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), train_dataset.cat_feature_idxs)\n",
    "])\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RAND_SEED)\n",
    "\n",
    "# gb = GradientBoostingClassifier(random_state=RAND_SEED)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('predictor', rf)  # gb\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits_count, max_trials, n_hparams_at_trial = 5, 10, 3\n",
    "skf = StratifiedKFold(n_splits=cv_splits_count, shuffle=True, random_state=RAND_SEED)\n",
    "search_spaces = {\n",
    "                    'predictor__n_estimators': [10, 50, 100, 200, 400, 600, 800],\n",
    "                    'predictor__max_depth': [None, 4, 6, 8, 10, 20, 30, 40, 50],\n",
    "                    'predictor__min_samples_split': [2, 5, 10, 15, 20],\n",
    "                    'predictor__min_samples_leaf': [1, 3, 5, 7, 10, 15],\n",
    "                    'predictor__min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "                    'predictor__max_features': ['sqrt', 'log2'],\n",
    "                    'predictor__max_leaf_nodes': [None, 10, 20, 30, 40, 50],\n",
    "                    'predictor__min_impurity_decrease': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "                }\n",
    "hparams_tuner = BayesSearchCV(estimator=pipeline,                                    \n",
    "                    search_spaces=search_spaces,                      \n",
    "                    scoring='f1',                                  \n",
    "                    cv=skf,                               # number of splits for cross-validation            \n",
    "                    n_iter=max_trials,                                # max number of trials\n",
    "                    n_points=n_hparams_at_trial,                      # number of hyperparameter sets evaluated at the same time\n",
    "                    iid=False,                                        # if not iid it optimizes on the cv score\n",
    "                    return_train_score=False,                         \n",
    "                    refit=False,                                      \n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},        # optmizer parameters: we use Gaussian Process (GP)\n",
    "                    n_jobs=-1,                                      \n",
    "                    random_state=RAND_SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "def onstep(res):\n",
    "    global counter\n",
    "    x0 = res.x_iters   # List of input points\n",
    "    y0 = res.func_vals # Evaluation of input points\n",
    "    print(f'Last eval #{counter}: {x0[-1]}', \n",
    "          f' - Score {y0[-1]:.3f}')\n",
    "    print(f' - Best Score {res.fun:.3f}',\n",
    "          f' - Best Args: {res.x}')\n",
    "    counter += 1\n",
    "\n",
    "overdone_control = DeltaYStopper(delta=0.0001)               # We stop if the gain of the optimization becomes too small\n",
    "time_limit_control = DeadlineStopper(total_time=60 * 45)     # We impose a time limit (45 minutes)\n",
    "\n",
    "callbacks=[overdone_control, time_limit_control, onstep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last eval #1: [20, 'sqrt', 50, 0.2, 5, 15, 0.3, 100]  - Score -0.000\n",
      " - Best Score -0.000  - Best Args: [10, 'log2', 30, 0.3, 15, 20, 0.0, 10]\n",
      "Last eval #2: [30, 'log2', 40, 0.0, 7, 10, 0.0, 200]  - Score -0.653\n",
      " - Best Score -0.653  - Best Args: [30, 'log2', 40, 0.0, 7, 10, 0.0, 200]\n",
      "Last eval #3: [40, 'log2', None, 0.1, 10, 15, 0.1, 100]  - Score -0.000\n",
      " - Best Score -0.653  - Best Args: [30, 'log2', 40, 0.0, 7, 10, 0.0, 200]\n",
      "Last eval #4: [4, 'log2', 20, 0.2, 10, 15, 0.4, 100]  - Score -0.000\n",
      " - Best Score -0.653  - Best Args: [30, 'log2', 40, 0.0, 7, 10, 0.0, 200]\n",
      "candidates checked: 10, best CV score: 0.653, best_score_std:0.007\n",
      "best_params: OrderedDict([('predictor__max_depth', 30), ('predictor__max_features', 'log2'), ('predictor__max_leaf_nodes', 40), ('predictor__min_impurity_decrease', 0.0), ('predictor__min_samples_leaf', 7), ('predictor__min_samples_split', 10), ('predictor__min_weight_fraction_leaf', 0.0), ('predictor__n_estimators', 200)])\n"
     ]
    }
   ],
   "source": [
    "X = train_dataset.feature_data()\n",
    "y = train_dataset.target_data\n",
    "hparams_tuner.fit(X, y, callback=callbacks)\n",
    "\n",
    "hparams_evals_count = len(hparams_tuner.cv_results_['params'])\n",
    "best_score = hparams_tuner.best_score_\n",
    "best_score_std = pd.DataFrame(hparams_tuner.cv_results_).iloc[hparams_tuner.best_index_].std_test_score\n",
    "best_params = hparams_tuner.best_params_\n",
    "print(f\"candidates checked: {hparams_evals_count}, best CV score: {best_score:.3f}, best_score_std:{best_score_std:.3f}\")\n",
    "print(f\"best_params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, RobustScaler(),\n",
       "                                                  [1, 2, 3, 4, 6, 7, 8, 9, 10,\n",
       "                                                   11, 13, 16, 17, 19]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [0, 5, 12, 14, 15, 18, 20,\n",
       "                                                   21])])),\n",
       "                (&#x27;predictor&#x27;,\n",
       "                 RandomForestClassifier(max_depth=30, max_features=&#x27;log2&#x27;,\n",
       "                                        max_leaf_nodes=40, min_samples_leaf=7,\n",
       "                                        min_samples_split=10, n_estimators=200,\n",
       "                                        random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, RobustScaler(),\n",
       "                                                  [1, 2, 3, 4, 6, 7, 8, 9, 10,\n",
       "                                                   11, 13, 16, 17, 19]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [0, 5, 12, 14, 15, 18, 20,\n",
       "                                                   21])])),\n",
       "                (&#x27;predictor&#x27;,\n",
       "                 RandomForestClassifier(max_depth=30, max_features=&#x27;log2&#x27;,\n",
       "                                        max_leaf_nodes=40, min_samples_leaf=7,\n",
       "                                        min_samples_split=10, n_estimators=200,\n",
       "                                        random_state=0))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, RobustScaler(),\n",
       "                                 [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 16, 17,\n",
       "                                  19]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [0, 5, 12, 14, 15, 18, 20, 21])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 16, 17, 19]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RobustScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RobustScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[0, 5, 12, 14, 15, 18, 20, 21]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=30, max_features=&#x27;log2&#x27;, max_leaf_nodes=40,\n",
       "                       min_samples_leaf=7, min_samples_split=10,\n",
       "                       n_estimators=200, random_state=0)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', RobustScaler(),\n",
       "                                                  [1, 2, 3, 4, 6, 7, 8, 9, 10,\n",
       "                                                   11, 13, 16, 17, 19]),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  [0, 5, 12, 14, 15, 18, 20,\n",
       "                                                   21])])),\n",
       "                ('predictor',\n",
       "                 RandomForestClassifier(max_depth=30, max_features='log2',\n",
       "                                        max_leaf_nodes=40, min_samples_leaf=7,\n",
       "                                        min_samples_split=10, n_estimators=200,\n",
       "                                        random_state=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(**best_params)\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Wrap the Model and Evaluate Its Performance\n",
    "\n",
    "We wrap the chosen model pipeline (either the default pipeline or the SVC-based pipeline) using our standardized model wrapper. Then, we calculate the model's predictive performance on the test dataset and print the resulting performance metric name and score. This step ensures that our trained model meets the evaluation criteria before proceeding to domain rule verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance Metric : F1-Score=0.6343638525564804\n"
     ]
    }
   ],
   "source": [
    "model_wrapper.wrap_model(pipeline) # or svc_pipeline \n",
    "metric_name, metric_score = model_wrapper.calculate_predictive_performance(test_dataset)\n",
    "print(f\"Test Performance Metric : {metric_name}={metric_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Loading or Generating the Domain Configuration\n",
    "\n",
    "VerifIA allows you to create a domain configuration in two way. With the domain configuration available (either generated or loaded), we instantiate the `RuleConsistencyVerifier`. This verifier uses the domain rules and constraints to evaluate whether the model’s predictions on the test data are consistent with our domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Option A: Predefined Domain File:**  \n",
    "A pre-defined YAML file (e.g., \"hotel_cancellation.yaml\") can be loaded directly to provide the domain constraints and rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_PATH = f\"../domains/hotel_cancellation.yaml\"\n",
    "model_verifier = RuleConsistencyVerifier(DOMAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Option B: AI-Powered Domain Generation:**  \n",
    "Using the `DomainGenFlow` module, the domain configuration can be generated automatically by providing the training data, descriptive domain knowledge (from external documents located in a PDF directory), and the model card.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup OpenAI and LangSmith Keys**\n",
    "\n",
    "Note that LangSmith is not needed, but it is helpful. If you do want to use LangSmith, after you sign up at the link above, make sure to set your environment variables to start logging traces.\n",
    "\n",
    "Accessing the OpenAI API requires an API key, which you can get by creating an account. Once you have a key you'll want to set it as an environment variable by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(prompt='Your LANGCHAIN_API_KEY? ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt='Your OPENAI_API_KEY? ')\n",
    "os.environ[\"USER_AGENT\"] = 'my_agent'\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = 'VERIFIA_TEST'\n",
    "os.environ[\"VERIFIA_GPT_NAME\"] = 'gpt-4.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mverifia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DomainGenFlow\n\u001b[0;32m      2\u001b[0m DOMAIN_PDF_DIRPATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../documents/hotel_cancellation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m domain_genflow \u001b[38;5;241m=\u001b[39m DomainGenFlow()\n",
      "File \u001b[1;32mc:\\Users\\Houssem\\Downloads\\verifia\\.venv\\lib\\site-packages\\verifia\\generation\\__init__.py:13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use AI generation you must install with extra genflow: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install verifia[torch]`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflows\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DomainGenFlow\n",
      "File \u001b[1;32mc:\\Users\\Houssem\\Downloads\\verifia\\.venv\\lib\\site-packages\\verifia\\generation\\flows.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Command\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_dataframe_agent, create_retriever_agent\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     create_chroma_vectorstore_from_pdfs,\n\u001b[0;32m     13\u001b[0m     create_chroma_vectorstore_from_string,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mverifia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_yaml, save_yaml\n",
      "File \u001b[1;32mc:\\Users\\Houssem\\Downloads\\verifia\\.venv\\lib\\site-packages\\verifia\\generation\\agents.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_pdf_retriever_tool\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DomainGraphState\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT_MODEL\n\u001b[0;32m     15\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(level\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOG_LEVEL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Houssem\\Downloads\\verifia\\.venv\\lib\\site-packages\\verifia\\generation\\gpts.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m GPT_MODEL_NAME \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERIFIA_GPT_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m GPT_MODEL_TEMP \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERIFIA_GPT_TEMPERATURE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m GPT_MODEL \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPT_MODEL_TEMP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPT_MODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m MAX_RETRIES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERIFIA_VALIDATOR_MAX_RETRIES\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Houssem\\Downloads\\verifia\\.venv\\lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Houssem\\Downloads\\verifia\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:625\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(\n\u001b[0;32m    622\u001b[0m             proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy, verify\u001b[38;5;241m=\u001b[39mglobal_ssl_context\n\u001b[0;32m    623\u001b[0m         )\n\u001b[0;32m    624\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msync_specific)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32mc:\\Users\\Houssem\\Downloads\\verifia\\.venv\\lib\\site-packages\\openai\\_client.py:124\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    122\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from verifia.generation import DomainGenFlow\n",
    "\n",
    "DOMAIN_PDF_DIRPATH = \"../documents/hotel_cancellation\"\n",
    "domain_genflow = DomainGenFlow()\n",
    "domain_genflow.load_ctx(dataframe=train_dataset.data, \n",
    "                        pdfs_dirpath=DOMAIN_PDF_DIRPATH,\n",
    "                        model_card=model_wrapper.model_card.to_dict())\n",
    "domain_cfg_dict = domain_genflow.run()\n",
    "model_verifier = RuleConsistencyVerifier(domain_cfg_dict=domain_cfg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Running the Verification Process\n",
    "\n",
    "The verifier is connected to the wrapped model and test dataset. In this example, the verification is executed using a Random Sampler (RS) as the search algorithm with specified parameters:\n",
    "- **Population Size:** 50\n",
    "- **Maximum Iterations:** 10\n",
    "- **Original Seed Size:** 100\n",
    "\n",
    "This process explores the input space to identify any instances where the model’s predictions violate the established rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Original Inputs: 17it [00:00, 21.33it/s]it/s]\n",
      "Processing Original Inputs: 17it [00:00, 21.16it/s]3,  1.25it/s]\n",
      "Processing Original Inputs: 17it [00:00, 21.31it/s]2,  1.24it/s]\n",
      "Processing Original Inputs: 17it [00:00, 19.24it/s]2,  1.24it/s]\n",
      "Processing Original Inputs: 17it [00:00, 18.98it/s]1,  1.19it/s]\n",
      "Processing Original Inputs: 17it [00:00, 20.43it/s]1,  1.16it/s]\n",
      "Processing Original Inputs: 17it [00:00, 21.43it/s]0,  1.17it/s]\n",
      "Processing Original Inputs: 17it [00:01, 14.82it/s]9,  1.20it/s]\n",
      "Processing Original Inputs: 17it [00:00, 19.93it/s]9,  1.07it/s]\n",
      "Processing Original Inputs: 17it [00:00, 17.34it/s]8,  1.10it/s]\n",
      "Processing Original Inputs: 17it [00:00, 18.13it/s]07,  1.07it/s]\n",
      "Processing Original Inputs: 17it [00:00, 18.61it/s]06,  1.07it/s]\n",
      "Processing Original Inputs: 17it [00:01, 14.98it/s]05,  1.07it/s]\n",
      "Processing Original Inputs: 17it [00:01, 12.91it/s]04,  1.01it/s]\n",
      "Processing Original Inputs: 17it [00:01, 13.05it/s]04,  1.09s/it]\n",
      "Processing Original Inputs: 17it [00:01, 13.03it/s]03,  1.16s/it]\n",
      "Processing Original Inputs: 17it [00:01, 12.16it/s]02,  1.21s/it]\n",
      "Processing Original Inputs: 17it [00:01, 11.99it/s]01,  1.27s/it]\n",
      "Processing Rules: 100%|██████████| 18/18 [00:18<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "result:RulesViolationResult = model_verifier.verify(model_wrapper)\\\n",
    "                                            .on(test_dataset.data)\\\n",
    "                                            .using(\"RS\")\\\n",
    "                                            .run(pop_size=4, max_iters=3, orig_seed_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Saving the Verification Report and Model Artifacts\n",
    "\n",
    "Finally, the verification results are saved as an HTML report, which provides a detailed summary of rule compliance and any detected inconsistencies. Additionally, the trained model and its model card are saved for future reference, ensuring that your work is reproducible and that the model’s verification status is archived.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save_as_html(\"../reports/hotel_cancellation.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.save_model()\n",
    "model_wrapper.save_model_card(\"../models/hotel_cancellation.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
