{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VerifIA","text":"<p>VerifIA is an open-source AI testing framework for domain\u2011aware verification of machine\u2011learning models during the staging phase\u2014before deployment.</p> <p>Definition: The staging phase encompasses model training on the training set, hyperparameter tuning on the validation set, and performance evaluation on the test set. During this phase, models must satisfy domain-specific requirements and regulatory standards before advancing to production.</p> <ul> <li>Source Code: github.com/VerifIA/verifia</li> </ul> <p>Fundamentally, VerifIA automates a structured sequence of verifications to assess model consistency with domain knowledge. At the end of each run, it generates a validation report to:</p> <ol> <li>Inform deployment decisions by operations teams.</li> <li>Guide engineers in debugging and enhancing pipeline robustness.</li> </ol>"},{"location":"#why-verifia","title":"Why VerifIA?","text":"<p>Most production AI systems today rely on mature, open\u2011source frameworks\u2014scikit\u2011learn, LightGBM, CatBoost, XGBoost, PyTorch, TensorFlow\u2014that keep pace with the latest research and hardware accelerators. While these libraries empower practitioners to build state\u2011of\u2011the\u2011art models on large datasets, many organizations struggle to fully understand or control the resulting systems.  </p> <ul> <li>Rush to Adopt: Businesses integrating AI into existing analytics workflows often end up with only a partial grasp of model behavior.  </li> <li>Regulatory Pressure: Rising public concern has led to AI\u2011specific policies and soft laws mandating compliance with human\u2011centered legal requirements.  </li> <li>Safety\u2011Critical Caution: Industries with zero\u2011tolerance for failure (e.g. aerospace, healthcare) have hesitated to deploy AI without rigorous quality assurance.  </li> </ul> <p>Even rare but catastrophic AI failures\u2014whether due to distributional shifts, spurious correlations, or untested edge cases\u2014are unacceptable in many domains.</p> <p>VerifIA brings domain\u2011aware model verification to your staging pipeline:</p> <ol> <li> <p>Seamless Integration </p> <ul> <li>Model frameworks: scikit\u2011learn, LightGBM, CatBoost, XGBoost, PyTorch, TensorFlow </li> <li>Model registries: MLflow, Comet\u00a0ML, Weights\u00a0&amp;\u00a0Biases </li> </ul> </li> <li> <p>AI\u2011Assisted Domain Creation </p> <ul> <li>Draft your domain YAML (variables, constraints, rules) automatically from sample data and documents  </li> <li>Compatible with any LLM via LangChain (e.g. OpenAI, Anthropic, or on\u2011premise models)  </li> </ul> </li> <li> <p>Systematic Verification </p> <ul> <li>Run a battery of rule\u2011consistency checks derived from your domain knowledge  </li> <li>Explore out\u2011of\u2011sample, in\u2011domain edge cases via population\u2011based searchers  </li> </ul> </li> <li> <p>Actionable Reports </p> <ul> <li>Generate an interactive validation report linked back to your staging model  </li> <li>Operators decide deployment readiness  </li> <li>Engineers gain debugging insights and quality\u2011improvement guidance  </li> </ul> </li> </ol>"},{"location":"#verifia-testing-workflow-arrangeactassert","title":"VerifIA Testing Workflow (Arrange\u2013Act\u2013Assert)","text":"<p>VerifIA adopts the well-known Arrange\u2013Act\u2013Assert pattern from software testing, adapted for AI model verification:</p> <ol> <li> <p>Arrange:</p> <ul> <li>Define application-specific expectations\u2014the domain expert\u2019s assertions about correct model behavior.</li> <li>Structure these assertions into a formal, machine-verifiable format.</li> </ul> </li> <li> <p>Act:</p> <ul> <li>Generate synthetic input samples that reflect the original data distribution and explore beyond it.</li> <li>Support targeted generation within specific input subspaces for deeper analysis.</li> </ul> </li> <li> <p>Assert:</p> <ul> <li>Evaluate the model\u2019s responses against the arranged expectations.</li> <li>Quantify compliance levels to identify safe operational domains and uncover inconsistencies.</li> </ul> </li> </ol>"},{"location":"#aipowered-domain-generation","title":"AI\u2011Powered Domain Generation","text":"\ud83d\ude80 Preview: VerifIA Domain Spec Generator UI Fig. 1: Real\u2011time domain YAML generation &amp; validation. <p>Forget manual YAML editing\u2014VerifIA can auto\u2011draft your entire domain spec in minutes. </p> <p>Using LangChain\u2011compatible LLMs, it ingests:</p> <ul> <li>Your data (CSV, Parquet, DataFrame)  </li> <li>Your documentation (PDFs, or vectordb)  </li> <li>Your model card (YAML file or dict)</li> </ul> <p>It then generates a ready\u2011to\u2011use <code>domain.yaml</code> that includes:</p> <ol> <li>Variable definitions (types, real\u2011world ranges)  </li> <li>Feasibility constraints (inter\u2011feature formulas)  </li> <li>Behavioral rules (premises \u2192 conclusions)  </li> </ol> <p>Human\u2011in\u2011the\u2011Loop Experience</p> <p>Through the built\u2011in Gradio interface, you can:</p> <ul> <li>Review the AI\u2011drafted spec side\u2011by\u2011side.  </li> <li>Edit any section inline.  </li> <li>Regenerate specific parts on demand.  </li> <li>Validate against your schema before export. </li> </ul> <p>\ud83d\udc49 Dive into the AI\u2011Based Domain Generation Guide for a full walkthrough.  </p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Install VerifIA and run your first verification in minutes:</p> <pre><code>pip install verifia\n</code></pre> <pre><code>from verifia.verification import RuleConsistencyVerifier\n\n# 1. Arrange: load your domain rules\nverifier = RuleConsistencyVerifier(\"domain_rules.yaml\")\n\n# 2. Act: attach model (card or dict) + data\nreport = (\n    verifier\n      .verify(model_card_fpath_or_dict=\"model_card.yaml\")\n      .on(data_fpath=\"test_data.csv\")        # .csv, .json, .xlsx, .parquet, .feather, .pkl\n      .using(\"GA\")                           # RS, FFA, MFO, GWO, MVO, PSO, WOA, GA, SSA\n      .run(pop_size=50, max_iters=100)       # search budget\n)\n\n# 3. Assert: save and inspect your report\nreport.save_as_html(\"verification_report.html\")\n</code></pre> <p>\ud83d\udc49 Quickstart guide</p>"},{"location":"#learn-verifia","title":"Learn VerifIA","text":"<ul> <li> <p> Concepts</p> <p>Explore VerifIA\u2019s core abstractions\u2014Data, Model, Domain, Searcher, and Run\u2014to understand how they interconnect.</p> <p> View Concepts</p> </li> <li> <p> Tutorials</p> <p>Hands\u2011on walkthroughes that guide you through the core components of VerifIA on simplified examples.</p> <p> Start Tutorials</p> </li> <li> <p> Guides</p> <p>Deep\u2011dive guides on domain creation, AI\u2011Based Domain Generation, and configuration.</p> <p> Read Guides</p> </li> <li> <p> Use Cases</p> <p>Discover how teams in finance, healthcare, and beyond can leverage VerifIA to boost model reliability.</p> <p> Explore Use Cases</p> </li> </ul>"},{"location":"#contribute","title":"Contribute","text":"<p>Help us improve VerifIA</p> <p>Feel free to:</p> <ul> <li>Report a Bug </li> <li>Report an Issue </li> <li>Request a Change </li> <li>Make a Pull Request</li> </ul> <p>If you find VerifIA useful, please give us a star on \u2b50\ufe0fGitHub\u2b50\ufe0f!</p>"},{"location":"#license","title":"License","text":"<p>VerifIA Tool is available under:</p> License Description AGPL\u20113.0 Community\u2011driven, OSI\u2011approved open\u2011source license Enterprise Commercial license for proprietary integration (no AGPL obligations). Mail to contact@verifia.ai. <p>We champion open source by returning all improvements back to the community \u2764\ufe0f. Your contributions help advance the field for everyone.</p>"},{"location":"enterprise-support/","title":"Enterprise Feedback","text":"<p>We value the insights of our enterprise users and want to learn how VerifIA fits into your model\u2011verification workflows. Your feedback helps us shape the tool and documentation to better serve real\u2011world needs.</p>"},{"location":"enterprise-support/#what-wed-love-to-hear","title":"What We\u2019d Love to Hear","text":"<ul> <li>Use cases: What projects or pipelines are you integrating VerifIA into?  </li> <li>Strengths: Which features or concepts have been most valuable?  </li> <li>Pain points: Where did you struggle\u2014installation, configuration, domain definition, search performance?  </li> <li>Wish list: What enhancements or new capabilities would make VerifIA more effective for your team?</li> </ul>"},{"location":"enterprise-support/#how-to-connect","title":"How to Connect","text":"<p>If you\u2019re an enterprise user and would like to share your experience, please email us at contact@verifia.ai with:</p> <ul> <li>Company name </li> <li>How you\u2019re using VerifIA (e.g. \u201cverifying credit\u2011scoring models\u201d or \u201cauditing production classifiers\u201d)  </li> <li>Topics or questions you\u2019d like to discuss  </li> </ul> <p>We\u2019ll follow up to schedule a 30\u2011minute call. This conversation is not technical support\u2014it\u2019s an open dialogue to understand your workflows, challenges, and ideas.</p> <p>Thank you for helping us build a stronger, more user\u2011focused VerifIA! </p>"},{"location":"license/","title":"License","text":"<p>GNU Affero General Public License v3.0</p> <pre><code>                GNU AFFERO GENERAL PUBLIC LICENSE\n                   Version 3, 19 November 2007\n</code></pre> <p>Copyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/  Everyone is permitted to copy and distribute verbatim copies  of this license document, but changing it is not allowed.</p> <pre><code>                        Preamble\n</code></pre> <p>The GNU Affero General Public License is a free, copyleft license for software and other kinds of works, specifically designed to ensure cooperation with the community in the case of network server software.</p> <p>The licenses for most software and other practical works are designed to take away your freedom to share and change the works.  By contrast, our General Public Licenses are intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users.</p> <p>When we speak of free software, we are referring to freedom, not price.  Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.</p> <p>Developers that use our General Public Licenses protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License which gives you legal permission to copy, distribute and/or modify the software.</p> <p>A secondary benefit of defending all users' freedom is that improvements made in alternate versions of the program, if they receive widespread use, become available for other developers to incorporate.  Many developers of free software are heartened and encouraged by the resulting cooperation.  However, in the case of software used on network servers, this result may fail to come about. The GNU General Public License permits making a modified version and letting the public access it on a server without ever releasing its source code to the public.</p> <p>The GNU Affero General Public License is designed specifically to ensure that, in such cases, the modified source code becomes available to the community.  It requires the operator of a network server to provide the source code of the modified version running there to the users of that server.  Therefore, public use of a modified version, on a publicly accessible server, gives the public access to the source code of the modified version.</p> <p>An older license, called the Affero General Public License and published by Affero, was designed to accomplish similar goals.  This is a different license, not a version of the Affero GPL, but Affero has released a new version of the Affero GPL which permits relicensing under this license.</p> <p>The precise terms and conditions for copying, distribution and modification follow.</p> <pre><code>                   TERMS AND CONDITIONS\n</code></pre> <ol> <li>Definitions.</li> </ol> <p>\"This License\" refers to version 3 of the GNU Affero General Public License.</p> <p>\"Copyright\" also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.</p> <p>\"The Program\" refers to any copyrightable work licensed under this License.  Each licensee is addressed as \"you\".  \"Licensees\" and \"recipients\" may be individuals or organizations.</p> <p>To \"modify\" a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy.  The resulting work is called a \"modified version\" of the earlier work or a work \"based on\" the earlier work.</p> <p>A \"covered work\" means either the unmodified Program or a work based on the Program.</p> <p>To \"propagate\" a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy.  Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.</p> <p>To \"convey\" a work means any kind of propagation that enables other parties to make or receive copies.  Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.</p> <p>An interactive user interface displays \"Appropriate Legal Notices\" to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License.  If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.</p> <ol> <li>Source Code.</li> </ol> <p>The \"source code\" for a work means the preferred form of the work for making modifications to it.  \"Object code\" means any non-source form of a work.</p> <p>A \"Standard Interface\" means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.</p> <p>The \"System Libraries\" of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form.  A \"Major Component\", in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.</p> <p>The \"Corresponding Source\" for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities.  However, it does not include the work's System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work.  For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.</p> <p>The Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.</p> <p>The Corresponding Source for a work in source code form is that same work.</p> <ol> <li>Basic Permissions.</li> </ol> <p>All rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met.  This License explicitly affirms your unlimited permission to run the unmodified Program.  The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work.  This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.</p> <p>You may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force.  You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright.  Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.</p> <p>Conveying under any other circumstances is permitted solely under the conditions stated below.  Sublicensing is not allowed; section 10 makes it unnecessary.</p> <ol> <li>Protecting Users' Legal Rights From Anti-Circumvention Law.</li> </ol> <p>No covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.</p> <p>When you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work's users, your or third parties' legal rights to forbid circumvention of technological measures.</p> <ol> <li>Conveying Verbatim Copies.</li> </ol> <p>You may convey verbatim copies of the Program's source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.</p> <p>You may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.</p> <ol> <li>Conveying Modified Source Versions.</li> </ol> <p>You may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:</p> <pre><code>a) The work must carry prominent notices stating that you modified\nit, and giving a relevant date.\n\nb) The work must carry prominent notices stating that it is\nreleased under this License and any conditions added under section\n7.  This requirement modifies the requirement in section 4 to\n\"keep intact all notices\".\n\nc) You must license the entire work, as a whole, under this\nLicense to anyone who comes into possession of a copy.  This\nLicense will therefore apply, along with any applicable section 7\nadditional terms, to the whole of the work, and all its parts,\nregardless of how they are packaged.  This License gives no\npermission to license the work in any other way, but it does not\ninvalidate such permission if you have separately received it.\n\nd) If the work has interactive user interfaces, each must display\nAppropriate Legal Notices; however, if the Program has interactive\ninterfaces that do not display Appropriate Legal Notices, your\nwork need not make them do so.\n</code></pre> <p>A compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an \"aggregate\" if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation's users beyond what the individual works permit.  Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.</p> <ol> <li>Conveying Non-Source Forms.</li> </ol> <p>You may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:</p> <pre><code>a) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by the\nCorresponding Source fixed on a durable physical medium\ncustomarily used for software interchange.\n\nb) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by a\nwritten offer, valid for at least three years and valid for as\nlong as you offer spare parts or customer support for that product\nmodel, to give anyone who possesses the object code either (1) a\ncopy of the Corresponding Source for all the software in the\nproduct that is covered by this License, on a durable physical\nmedium customarily used for software interchange, for a price no\nmore than your reasonable cost of physically performing this\nconveying of source, or (2) access to copy the\nCorresponding Source from a network server at no charge.\n\nc) Convey individual copies of the object code with a copy of the\nwritten offer to provide the Corresponding Source.  This\nalternative is allowed only occasionally and noncommercially, and\nonly if you received the object code with such an offer, in accord\nwith subsection 6b.\n\nd) Convey the object code by offering access from a designated\nplace (gratis or for a charge), and offer equivalent access to the\nCorresponding Source in the same way through the same place at no\nfurther charge.  You need not require recipients to copy the\nCorresponding Source along with the object code.  If the place to\ncopy the object code is a network server, the Corresponding Source\nmay be on a different server (operated by you or a third party)\nthat supports equivalent copying facilities, provided you maintain\nclear directions next to the object code saying where to find the\nCorresponding Source.  Regardless of what server hosts the\nCorresponding Source, you remain obligated to ensure that it is\navailable for as long as needed to satisfy these requirements.\n\ne) Convey the object code using peer-to-peer transmission, provided\nyou inform other peers where the object code and Corresponding\nSource of the work are being offered to the general public at no\ncharge under subsection 6d.\n</code></pre> <p>A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.</p> <p>A \"User Product\" is either (1) a \"consumer product\", which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling.  In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage.  For a particular product received by a particular user, \"normally used\" refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product.  A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.</p> <p>\"Installation Information\" for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source.  The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.</p> <p>If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information.  But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).</p> <p>The requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed.  Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.</p> <p>Corresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.</p> <ol> <li>Additional Terms.</li> </ol> <p>\"Additional permissions\" are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law.  If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.</p> <p>When you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it.  (Additional permissions may be written to require their own removal in certain cases when you modify the work.)  You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.</p> <p>Notwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:</p> <pre><code>a) Disclaiming warranty or limiting liability differently from the\nterms of sections 15 and 16 of this License; or\n\nb) Requiring preservation of specified reasonable legal notices or\nauthor attributions in that material or in the Appropriate Legal\nNotices displayed by works containing it; or\n\nc) Prohibiting misrepresentation of the origin of that material, or\nrequiring that modified versions of such material be marked in\nreasonable ways as different from the original version; or\n\nd) Limiting the use for publicity purposes of names of licensors or\nauthors of the material; or\n\ne) Declining to grant rights under trademark law for use of some\ntrade names, trademarks, or service marks; or\n\nf) Requiring indemnification of licensors and authors of that\nmaterial by anyone who conveys the material (or modified versions of\nit) with contractual assumptions of liability to the recipient, for\nany liability that these contractual assumptions directly impose on\nthose licensors and authors.\n</code></pre> <p>All other non-permissive additional terms are considered \"further restrictions\" within the meaning of section 10.  If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term.  If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.</p> <p>If you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.</p> <p>Additional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.</p> <ol> <li>Termination.</li> </ol> <p>You may not propagate or modify a covered work except as expressly provided under this License.  Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).</p> <p>However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.</p> <p>Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.</p> <p>Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License.  If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.</p> <ol> <li>Acceptance Not Required for Having Copies.</li> </ol> <p>You are not required to accept this License in order to receive or run a copy of the Program.  Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance.  However, nothing other than this License grants you permission to propagate or modify any covered work.  These actions infringe copyright if you do not accept this License.  Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.</p> <ol> <li>Automatic Licensing of Downstream Recipients.</li> </ol> <p>Each time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License.  You are not responsible for enforcing compliance by third parties with this License.</p> <p>An \"entity transaction\" is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations.  If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party's predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.</p> <p>You may not impose any further restrictions on the exercise of the rights granted or affirmed under this License.  For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.</p> <ol> <li>Patents.</li> </ol> <p>A \"contributor\" is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based.  The work thus licensed is called the contributor's \"contributor version\".</p> <p>A contributor's \"essential patent claims\" are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version.  For purposes of this definition, \"control\" includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.</p> <p>Each contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor's essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.</p> <p>In the following three paragraphs, a \"patent license\" is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement).  To \"grant\" such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.</p> <p>If you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients.  \"Knowingly relying\" means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient's use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.</p> <p>If, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.</p> <p>A patent license is \"discriminatory\" if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License.  You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.</p> <p>Nothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.</p> <ol> <li>No Surrender of Others' Freedom.</li> </ol> <p>If conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License.  If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all.  For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.</p> <ol> <li>Remote Network Interaction; Use with the GNU General Public License.</li> </ol> <p>Notwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software.  This Corresponding Source shall include the Corresponding Source for any work covered by version 3 of the GNU General Public License that is incorporated pursuant to the following paragraph.</p> <p>Notwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU General Public License into a single combined work, and to convey the resulting work.  The terms of this License will continue to apply to the part which is the covered work, but the work with which it is combined will remain governed by version 3 of the GNU General Public License.</p> <ol> <li>Revised Versions of this License.</li> </ol> <p>The Free Software Foundation may publish revised and/or new versions of the GNU Affero General Public License from time to time.  Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.</p> <p>Each version is given a distinguishing version number.  If the Program specifies that a certain numbered version of the GNU Affero General Public License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation.  If the Program does not specify a version number of the GNU Affero General Public License, you may choose any version ever published by the Free Software Foundation.</p> <p>If the Program specifies that a proxy can decide which future versions of the GNU Affero General Public License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Program.</p> <p>Later license versions may give you additional or different permissions.  However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.</p> <ol> <li>Disclaimer of Warranty.</li> </ol> <p>THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.</p> <ol> <li>Limitation of Liability.</li> </ol> <p>IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.</p> <ol> <li>Interpretation of Sections 15 and 16.</li> </ol> <p>If the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.</p> <pre><code>                 END OF TERMS AND CONDITIONS\n\n        How to Apply These Terms to Your New Programs\n</code></pre> <p>If you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.</p> <p>To do so, attach the following notices to the program.  It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the \"copyright\" line and a pointer to where the full notice is found.</p> <pre><code>&lt;one line to give the program's name and a brief idea of what it does.&gt;\nCopyright (C) &lt;year&gt;  &lt;name of author&gt;\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as published\nby the Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.\n</code></pre> <p>Also add information on how to contact you by electronic and paper mail.</p> <p>If your software can interact with users remotely through a computer network, you should also make sure that it provides a way for users to get its source.  For example, if your program is a web application, its interface could display a \"Source\" link that leads users to an archive of the code.  There are many ways you could offer source, and different solutions will be better for different programs; see section 13 for the specific requirements.</p> <p>You should also get your employer (if you work as a programmer) or school, if any, to sign a \"copyright disclaimer\" for the program, if necessary. For more information on this, and how to apply and follow the GNU AGPL, see https://www.gnu.org/licenses/.</p>"},{"location":"quickstart/","title":"Getting Started","text":"<p>Follow these steps to install VerifIA, wrap your model, define your domain, and run a verification.</p>"},{"location":"quickstart/#1-install","title":"1. Install","text":"PyPI (recommended)From GitHub (latest)Extras: AI\u2011Based Domain Generation <pre><code>pip install verifia\n</code></pre> <pre><code>git clone https://github.com/verifia/verifia.git\ncd verifia\npip install -e .\n</code></pre> <pre><code># For VerifIA to generate your domain spec, install the extra dependencies:\npip install verifia[genflow]\n</code></pre>"},{"location":"quickstart/#2-prepare-your-components","title":"2. Prepare Your Components","text":"<p>a. Domain Configuration Create <code>domain_rules.yaml</code> with three sections:</p> <ul> <li><code>variables</code>: feature &amp; target definitions</li> <li><code>constraints</code>: input\u2010only feasibility checks</li> <li><code>rules</code>: behavioral assertions (premises \u2192 conclusion)</li> </ul> <p>See Domain Creation Guide for full details.</p> <p>b. Model Card Create <code>model_card.yaml</code> describing your staging model. Below is an example:</p> <pre><code>name: your_model\nversion: '1'\ntype: regression\nframework: sklearn\nfeature_names:\n  - fearture_1\n  - fearture_2\n  - ...\ntarget_name: target\nlocal_dirpath: models\n</code></pre> <p>VerifIA will load <code>models/your_model-1.pkl</code> by default.</p> <p>Supported extensions:</p> Framework Extension sklearn <code>pkl</code> lightgbm <code>txt</code> catboost <code>cb</code> xgboost <code>json</code> pytorch <code>pth</code> tensorflow <code>keras</code> <p>However, you can set up exactly one of MLflow, Comet\u00a0ML, or Weights\u00a0&amp;\u00a0Biases via environment variables (see below) and VerifIA will auto\u2011load from your model registry.</p> MLflowComet MLWeights &amp; Biases <pre><code>export MLFLOW_TRACKING_URI=\"https://mlflow.example.com\"\n</code></pre> <pre><code>export COMET_API_KEY=\"&lt;key&gt;\" \\\n       COMET_WORKSPACE=\"&lt;workspace&gt;\" \\\n       COMET_PROJECT_NAME=\"&lt;project&gt;\"\n</code></pre> <pre><code>export WANDB_API_KEY=\"&lt;key&gt;\" \\\n       WANDB_PROJECT=\"&lt;project&gt;\" \\\n       WANDB_ENTITY=\"&lt;entity&gt;\"\n</code></pre>"},{"location":"quickstart/#3-run-a-verification","title":"3. Run a Verification","text":"<pre><code>from verifia.verification import RuleConsistencyVerifier\n\n# 1. Arrange: load your domain rules\nverifier = RuleConsistencyVerifier(\"domain_rules.yaml\")\n\n# 2. Act: attach model (card or dict) + data\nreport = (\n    verifier\n      .verify(model_card_fpath_or_dict=\"model_card.yaml\")\n      .on(data_fpath=\"test_data.csv\")        # .csv, .json, .xlsx, .parquet, .feather, .pkl\n      .using(\"GA\")                           # RS, FFA, MFO, GWO, MVO, PSO, WOA, GA, SSA\n      .run(pop_size=50, max_iters=100)       # search budget\n)\n\n# 3. Assert: save and inspect your report\nreport.save_as_html(\"verification_report.html\")\n</code></pre>"},{"location":"quickstart/#4-inspecting-results","title":"4. Inspecting Results","text":"<ul> <li>Open <code>verification_report.html</code> in your browser.</li> <li>Review consistency rates, compliance rates, and average deviations.</li> <li>Use <code>report.log_as_html(\"my_report\")</code> to attach the report to your model registry.</li> </ul>"},{"location":"quickstart/#5-ai-generated-domain","title":"5. AI-Generated Domain","text":"<p>Don\u2019t hand\u2011craft YAML by hand\u2014let VerifIA\u2019s <code>DomainGenFlow</code> do it for you in minutes. Point it at your data, docs, and model card, and you\u2019ll get a complete domain spec ready to verify.</p> \ud83d\ude80 Launch the Gradio Domain Spec Generator <p> Fig. Human\u2011in\u2011the\u2011loop draft \u2192 edit \u2192 validate via Gradio UI.     </p> <p>Spin up the full Gradio interface with a single call:</p> <pre><code>from verifia.generation import DomainGenFlow\n\nflow = DomainGenFlow()\nflow.load_ctx(\n    data_fpath=\"data/my_dataset.csv\",        # or dataframe=df\n    pdfs_dirpath=\"docs/domain_pdfs/\",        # or db_str_content / vectordb\n    model_card_fpath=\"model_card.yaml\"       # or model_card=dict(...)\n)\n# 4) Launch the interactive UI\nflow.launch()\n</code></pre> <p>What it does:</p> <p>Behind the scenes, VerifIA\u2019s <code>DomainGenFlow</code> will:</p> <ul> <li>Extract feature metadata via DataFrame agents</li> <li>Infer constraints &amp; rules from your documents via retriever agents</li> <li>Draft a fully\u2011formed YAML containing:<ul> <li>Variables (types, ranges)</li> <li>Constraints (inter\u2011feature formulas)</li> <li>Rules (premises \u2192 conclusions)</li> </ul> </li> <li>Let you review, edit, and regenerate any section before exporting</li> </ul> <p>Review, Refine, and then, Feed <code>domain_cfg_path</code> directly into <code>RuleConsistencyVerifier</code> or Save it as <code>generated_domain.yaml</code>.</p>"},{"location":"quickstart/#quick-links","title":"Quick Links","text":"<ul> <li>Concepts</li> <li>API Reference</li> <li>Tutorials</li> <li>Guides</li> <li>Use Cases</li> <li>Report a Bug</li> <li>Report a Docs Issue</li> <li>Request a Change</li> <li>Make a Pull Request</li> </ul>"},{"location":"use-cases/","title":"Use Case Gallery","text":"<p>Welcome to the VerifIA Use Case Gallery\u2014four end\u2011to\u2011end examples demonstrating how VerifIA can be applied to both regression and classification problems. Each use case includes a Jupyter notebook that guides you through:</p> <ul> <li>Wrapping a trained model  </li> <li>Loading a predefined domain YAML or generating one via AI  </li> <li>Running rule\u2011consistency verification  </li> <li>Interpreting and exporting results  </li> </ul> <p>By exploring these, you\u2019ll see how VerifIA adapts across data types, frameworks, and verification goals.</p>"},{"location":"use-cases/#regression-use-cases","title":"Regression Use Cases","text":""},{"location":"use-cases/#1-compressive-strength-regression-tensorflow","title":"1. Compressive Strength Regression (TensorFlow)","text":"<p>Verify a TensorFlow regression model trained on concrete compressive strength data. This guide demonstrates:</p> <ul> <li>Hyperparameter tuning with scikit-optimize </li> <li>Manual &amp; AI\u2011powered domain generation  </li> <li>Rule\u2011based verification with VerifIA </li> </ul> <p></p> <p>Artifacts:</p> <ul> <li>Dataset (CSV) </li> <li>Domain YAML </li> <li>Application-specific docs (Zipped PDFs) </li> </ul>"},{"location":"use-cases/#2-house-pricing-prediction-catboost","title":"2. House Pricing Prediction (CatBoost)","text":"<p>Verify a CatBoost regression model forecasting house prices. You will learn:</p> <ul> <li>Bayesian tuning with BayesSearchCV </li> <li>Wrapping CatBoost via <code>CBModel</code> </li> <li>Loading or generating a domain config  </li> <li>Verifying rule\u2011consistency with VerifIA </li> </ul> <p></p> <p>Artifacts:</p> <ul> <li>Dataset (CSV) </li> <li>Domain YAML </li> <li>Application-specific docs (Zipped PDFs) </li> </ul>"},{"location":"use-cases/#classification-use-cases","title":"Classification Use Cases","text":""},{"location":"use-cases/#3-hotel-cancellation-prediction-scikitlearn","title":"3. Hotel Cancellation Prediction (Scikit\u2011Learn)","text":"<p>Verify a Scikit\u2011Learn pipeline (SVC &amp; Random Forest) for predicting hotel cancellations. This walkthrough covers:</p> <ul> <li>Building preprocessing pipelines (<code>StandardScaler</code>, <code>OneHotEncoder</code>)  </li> <li>Tuning with <code>RandomizedSearchCV</code> &amp; <code>BayesSearchCV</code> </li> <li>Wrapping via <code>SKLearnModel</code> </li> <li>Domain config &amp; rule\u2011consistency verification  </li> </ul> <p></p> <p>Artifacts:</p> <ul> <li>Dataset (CSV) </li> <li>Domain YAML </li> <li>Application-specific docs (Zipped PDFs) </li> </ul>"},{"location":"use-cases/#4-loan-eligibility-classification-xgboost","title":"4. Loan Eligibility Classification (XGBoost)","text":"<p>Verify an XGBoost classifier for loan repayment prediction. In this example you will:</p> <ul> <li>Perform Bayesian hyperparameter tuning (<code>BayesSearchCV</code>)  </li> <li>Wrap using <code>XGBModel</code> </li> <li>Generate or load domain configurations  </li> <li>Run rule\u2011consistency checks  </li> </ul> <p></p> <p>Artifacts:</p> <ul> <li>Dataset (CSV) </li> <li>Domain YAML </li> <li>Application-specific docs (Zipped PDFs) </li> </ul>"},{"location":"use-cases/#why-use-cases","title":"Why Use Cases?","text":"<ul> <li>Hands\u2011on guidance: Detailed notebooks covering each step.  </li> <li>Framework diversity: TensorFlow, CatBoost, Scikit\u2011Learn, XGBoost.  </li> <li>Balanced scenarios: Two regression and two classification examples.  </li> <li>Best practices: Tips on tuning, domain setup, and result interpretation.</li> </ul> <p>Next Steps: 1. Choose the use case matching your problem type. 2. Clone the corresponding notebook and run it locally. 3. Adapt the patterns to verify your own models with VerifIA.</p>"},{"location":"community/","title":"Contributing to VerifIA","text":"<p>VerifIA is an open\u2011source project under active development. Your contributions\u2014whether reporting bugs, improving documentation, suggesting features, or submitting pull requests\u2014help us make the tool more robust, user\u2011friendly, and aligned with real\u2011world workflows.  </p> <p>Our community thrives when contributions are well\u2011structured, clear, and easy to review. This guide will help you pick the right path and template for your contribution.</p>"},{"location":"community/#how-you-can-contribute","title":"How You Can Contribute","text":""},{"location":"community/#1-report-a-bug","title":"1. Report a Bug","text":"<p>Found unexpected behavior or an error in VerifIA? Please help us by following the bug report guide.  </p>"},{"location":"community/#2-report-a-docs-issue","title":"2. Report a Docs Issue","text":"<p>Spotted a typo, inconsistency, or missing detail in the documentation? Open a docs issue so we can clarify or expand the docs.  </p>"},{"location":"community/#3-request-a-change","title":"3. Request a Change","text":"<p>Have an idea for a new feature or enhancement? Share your proposal via a change request issue.  </p>"},{"location":"community/#4-create-a-pull-request","title":"4. Create a Pull Request","text":"<p>Ready to contribute code or docs? See our pull request instructions to learn how to fork, branch, and submit a PR.  </p>"},{"location":"community/#before-you-file-an-issue","title":"Before You File an Issue","text":"<p>Please take a moment to:</p> <ul> <li>\ud83d\udd0d Search existing issues to avoid duplicates.  </li> <li>\ud83d\udce6 Update to the latest VerifIA version\u2014your issue may already be fixed.  </li> <li>\ud83d\udcdd Choose the appropriate template (bug, docs, change request) when opening a new issue.  </li> <li>\ud83e\udde9 Provide all necessary details (steps to reproduce, minimal example, environment) so we can triage quickly.  </li> </ul> <p>Issues are permanent</p> <p>All issues and comments are publicly visible and stored long\u2011term. Please be respectful, constructive, and follow our Code of Conduct.  </p>"},{"location":"community/#pull-request-workflow","title":"Pull Request Workflow","text":"<ol> <li>Fork the repository and clone your fork locally.  </li> <li>Create a branch for your work (<code>feature/...</code>, <code>bugfix/...</code>, <code>docs/...</code>).  </li> <li>Commit small, focused changes with clear messages.  </li> <li>Push to your fork and open a draft PR early\u2014reference the related issue.  </li> <li>Sync with <code>upstream/main</code> regularly to avoid merge conflicts.  </li> <li>Mark as ready when your PR is complete and request a review.  </li> </ol> <p>For full details and examples, see [making a pull request].</p>"},{"location":"community/#checklist","title":"Checklist","text":"<p>Before submitting, please confirm:</p> <ul> <li> I\u2019ve selected the correct issue template or PR workflow.  </li> <li> I searched existing issues and docs for related discussions.  </li> <li> I provided a clear title and description.  </li> <li> I included minimal, reproducible examples (if filing a bug).  </li> <li> I linked to related issues or documentation pages.  </li> <li> My changes follow the project\u2019s style and conventions.  </li> </ul>"},{"location":"community/#code-of-conduct","title":"Code of Conduct","text":"<p>Our Code of Conduct outlines the expectation for all community members to treat one another with respect, employing inclusive and welcoming language. Our commitment is to foster a positive and supportive environment, free of inappropriate, offensive, or harmful behavior.</p> <p>We take any violations seriously and will take appropriate action in response to uphold these values.</p> <p>Warning and Blocking Policy: To maintain a respectful and constructive community as VerifIA grows, we follow a three\u2011step process for handling serious or repeated misconduct:</p> <ol> <li> <p>First Warning    Users exhibiting inappropriate, offensive, or harmful behavior receive a formal notice that their actions violate our Code of Conduct. This warning is recorded permanently.</p> </li> <li> <p>Second Warning &amp; Resolution Period    If the behavior continues, a second warning is issued. The user then has five days to reflect and, if they choose, publicly address or apologize for their conduct. This period offers a chance to clear up misunderstandings.</p> </li> <li> <p>Blocking    If no improvement or response occurs after five days, we may block the user from our community and repository. This step is a last resort, taken only when necessary to protect our community\u2019s integrity.</p> </li> </ol> <p>Blocking remains extremely rare in our positive environment, underscoring our commitment to dialogue, respect, and mutual support.</p> <p>Thank you for helping improve VerifIA ! We look forward to your contributions.  </p>"},{"location":"community/making-a-pull-request/","title":"Making a Pull Request","text":"<p>You can contribute to VerifIA by opening a pull request against the main repository. Your changes\u2014whether bug fixes, documentation improvements, or new features\u2014will be reviewed by the maintainers and merged once approved.</p> <p>Before you begin</p> <ul> <li>If you\u2019ve found a bug, please open an issue first.</li> <li>For documentation updates, open a docs issue.</li> <li>For new features or behavior changes, open a feature request.</li> <li>Discuss your plan on the issue tracker so we can advise on scope and approach.</li> </ul>"},{"location":"community/making-a-pull-request/#1-learn-the-workflow","title":"1. Learn the Workflow","text":"<p>Before creating a pull request, get familiar with GitHub\u2019s PR concepts:</p> <ol> <li>Fork a repository </li> <li>Clone your fork </li> <li>Create a branch </li> <li>Push to your branch </li> <li>Open a pull request</li> </ol>"},{"location":"community/making-a-pull-request/#2-pull-request-process","title":"2. Pull Request Process","text":""},{"location":"community/making-a-pull-request/#21-prepare-your-changes","title":"2.1 Prepare your changes","text":"<pre><code>sequenceDiagram\n  autonumber\n  participant VerifIA\n  participant Fork\n  participant Local\n  participant PR\n\n  VerifIA -&gt;&gt; Fork: Fork `verifia/verifia`\n  Fork -&gt;&gt; Local: Clone fork\n  Local -&gt;&gt; Local: git switch -c feature/your-topic\n  loop develop\n    Local -&gt;&gt; Local: make edits &amp; commit\n    Local -&gt;&gt; Fork: git push\n    Fork -&gt;&gt; PR: open or update draft PR\n    PR -&gt;&gt; PR: review &amp; iterate\n  end</code></pre> <ol> <li>Fork the VerifIA repo <code>verifia/verifia</code>.</li> <li>Clone your fork locally:</li> </ol> <p><pre><code>git clone git@github.com:&lt;your_username&gt;/verifia.git\ncd verifia\n</code></pre> 3. Branch for your work:</p> <p><pre><code>git switch -c feature/describe-your-change\n</code></pre> 4. Develop with small, focused commits.</p> <ol> <li>Push often to your fork:</li> </ol> <p><pre><code>git push -u origin feature/describe-your-change\n</code></pre> 6. Open a draft PR as soon as you have something to show, while referencing an issue.</p>"},{"location":"community/making-a-pull-request/#22-keep-in-sync","title":"2.2 Keep in sync","text":"<p>If upstream <code>main</code> has new commits, merge them into your branch:</p> <pre><code>git remote add upstream https://github.com/verifia/verifia.git\ngit fetch upstream\ngit merge upstream/main\ngit push\n</code></pre>"},{"location":"community/making-a-pull-request/#3-finalizing-your-pull-request","title":"3. Finalizing Your Pull Request","text":"<pre><code>sequenceDiagram\n  autonumber\n  participant PR\n  participant VerifIA\n  participant Local\n\n  PR -&gt;&gt; PR: mark as ready for review\n  loop review\n    PR -&gt;&gt; Local: reviewer comments\n    Local -&gt;&gt; Local: address feedback &amp; commit\n    Local -&gt;&gt; Fork: git push\n  end\n  VerifIA -&gt;&gt; PR: maintainer merges (squash)\n  Local -&gt;&gt; Local: delete branch</code></pre> <ol> <li>Change from draft to ready for review.</li> <li>Receive reviews from a maintainer.</li> <li>Address feedback promptly with commits to your branch.</li> <li>Once approved, a maintainer will merge (often squashing commits).</li> </ol>"},{"location":"community/making-a-pull-request/#4-after-merge","title":"4. After Merge","text":"<ol> <li>Delete your topic branch both locally and on GitHub:</li> </ol> <p><pre><code>git switch main\ngit pull upstream main\ngit branch -d feature/describe-your-change\ngit push origin --delete feature/describe-your-change\n</code></pre> 2. You\u2019re ready for your next contribution!</p>"},{"location":"community/making-a-pull-request/#dos-and-donts","title":"Dos and Don\u2019ts","text":"<ul> <li> Do explain why you\u2019re making changes.</li> <li> Do reference related issues and discussions.</li> <li> Do write clear, descriptive commit messages.</li> <li> Don\u2019t submit huge, unreviewable diffs\u2014keep PRs small.</li> <li> Don\u2019t forget to merge upstream changes before finalizing.</li> </ul> <p>Thank you for helping build the VerifIA community! \ud83c\udf89</p>"},{"location":"community/reporting-a-bug/","title":"Reporting Bugs","text":"<p>VerifIA is an actively maintained open\u2011source tool. If you believe you\u2019ve found a bug, please help us by opening an issue on our public issue tracker. Follow this guide to include the information we need to diagnose and fix problems quickly.</p>"},{"location":"community/reporting-a-bug/#before-opening-an-issue","title":"Before Opening an Issue","text":"<p>With many users and contributors, duplicate or incomplete reports slow us down. Please do the following before filing a new bug report:</p>"},{"location":"community/reporting-a-bug/#1-upgrade-to-the-latest-version","title":"1. Upgrade to the Latest Version","text":"<p>Bugs are fixed rapidly. Ensure you\u2019re running the latest release of VerifIA. If not, update and see if the issue persists.</p>"},{"location":"community/reporting-a-bug/#2-search-for-existing-reports","title":"2. Search for Existing Reports","text":"<ul> <li>Documentation: Search our docs for related configuration or usage notes.</li> <li>Issues: Browse the issue tracker to see if someone else has reported the same problem.</li> </ul> <p>Keep track of your search terms and any relevant links\u2014you\u2019ll include them in your report.</p>"},{"location":"community/reporting-a-bug/#issue-template","title":"Issue Template","text":"<p>When you\u2019re sure the bug isn\u2019t already known or fixed, open a new issue using this template. Fill in each section as completely as possible.</p>"},{"location":"community/reporting-a-bug/#1-title","title":"1. Title","text":"<p>Short &amp; descriptive, e.g. \u201c<code>verify()</code> crashes when domain YAML has empty <code>constraints</code> block.\u201d</p>"},{"location":"community/reporting-a-bug/#2-context-optional","title":"2. Context\u00a0(optional)","text":"<p>Briefly explain your environment or use case. For example:</p> <p>Running VerifIA v1.2.0 on Ubuntu 22.04 with Python\u00a03.10, using a custom domain definition for robotic joint constraints.</p>"},{"location":"community/reporting-a-bug/#3-bug-description","title":"3. Bug Description","text":"<ul> <li>What happened? A concise summary of the unexpected behavior.</li> <li>Why it\u2019s a bug: Explain why this isn\u2019t intended VerifIA behavior.</li> </ul>"},{"location":"community/reporting-a-bug/#4-related-links","title":"4. Related Links","text":"<p>List any docs pages, errors, StackOverflow questions, or existing issues you\u2019ve found while investigating.</p>"},{"location":"community/reporting-a-bug/#5-reproduction","title":"5. Reproduction","text":"<p>Provide a minimal example (YAML, Python snippet, test data) that triggers the bug. Paste it directly or attach a <code>.zip</code> (\u22641\u202fMB).</p>"},{"location":"community/reporting-a-bug/#6-steps-to-reproduce","title":"6. Steps to Reproduce","text":"<p>Numbered steps showing exactly how to run your minimal example and observe the bug.</p> <ol> <li><code>pip install verifia==0.1.0</code> </li> <li>Create <code>domain.yaml</code> with\u2026  </li> <li>Run:    <pre><code>   verifier = ...\n</code></pre></li> </ol>"},{"location":"community/reporting-a-bug/#7-environment-optional","title":"7. Environment\u00a0(optional)","text":"<ul> <li>OS: e.g. Ubuntu\u00a022.04, Windows\u00a010</li> <li>Python: e.g. 3.9.7</li> <li>VerifIA: e.g. v0.1.0</li> <li>Additional packages: if relevant</li> </ul>"},{"location":"community/reporting-a-bug/#checklist","title":"Checklist","text":"<p>Before submitting, please confirm:</p> <ul> <li> I\u2019m on the latest VerifIA version</li> <li> I searched docs and existing issues</li> <li> My report includes a clear title and description</li> <li> I provided a minimal reproduction</li> <li> I listed exact steps to reproduce</li> <li> I attached relevant logs or error messages</li> </ul> <p>Thank you for helping make VerifIA more reliable !</p>"},{"location":"community/reporting-a-docs-issue/","title":"Documentation Issues","text":"<p>VerifIA\u2019s documentation spans concepts, API references, tutorials, and use cases. If you spot an inconsistency, typo, or see a way to improve clarity, please file a documentation issue on our issue tracker following this template.</p>"},{"location":"community/reporting-a-docs-issue/#issue-template","title":"Issue Template","text":"<p>Reporting a documentation issue is straightforward\u2014no reproduction needed. When opening a new issue, please include:</p> <ul> <li>Title </li> <li>Description </li> <li>Related links </li> <li>Proposed change (optional) </li> <li>Checklist</li> </ul>"},{"location":"community/reporting-a-docs-issue/#title","title":"Title","text":"<p>A concise one\u2011sentence summary highlighting the section and problem. Include keywords for easy searching.</p> Example \u2714\ufe0f Clear \u201cClarify <code>orig_seed_ratio</code> vs. <code>orig_seed_size</code> behavior\u201d \u274c Unclear \u201cSeed size issue\u201d \u274c Useless \u201cHelp needed\u201d"},{"location":"community/reporting-a-docs-issue/#description","title":"Description","text":"<p>Describe the documentation problem or inconsistency in one or two sentences. Explain why it\u2019s confusing or incorrect.</p> <ul> <li>Be specific: point out the exact section or wording.  </li> <li>One issue per report: separate unrelated items into different issues.</li> </ul> <p>Why we need this</p> <p>clear descriptions let us pinpoint and fix issues quickly.</p>"},{"location":"community/reporting-a-docs-issue/#related-links","title":"Related Links","text":"<p>Provide direct links (anchors) to the affected docs pages or sections. If similar issues exist elsewhere, link to those too.</p> <p>Why we need this</p> <p>links show us exactly where to apply improvements.</p>"},{"location":"community/reporting-a-docs-issue/#proposed-change-optional","title":"Proposed Change (optional)","text":"<p>Suggest how the text could be rewritten or reorganized. This helps maintainers and other contributors propose a fix faster.</p> <p>Why we need this</p> <p>concrete suggestions speed up the documentation update process.</p>"},{"location":"community/reporting-a-docs-issue/#checklist","title":"Checklist","text":"<p>Before submitting, please confirm:</p> <ul> <li> I\u2019ve searched the docs and existing issues  </li> <li> Title is clear and descriptive  </li> <li> Description pinpoints the problem  </li> <li> Related links are provided  </li> <li> Proposed change (if any) is outlined  </li> </ul> <p>Thank you for improving VerifIA\u2019s documentation! </p>"},{"location":"community/requesting-a-change/","title":"Change Requests","text":"<p>We welcome ideas for new features, enhancements, or workflow improvements. Before you file a change request, please read this guide so we can evaluate and prioritize your proposal effectively.</p>"},{"location":"community/requesting-a-change/#before-submitting","title":"Before Submitting","text":"<p>Please do the following preliminary work to ensure your idea fits VerifIA\u2019s scope and philosophy:</p> <ol> <li> <p>Not a bug    Change requests are for new features or behavior changes, not bug reports. If you\u2019ve found a bug, see our bug report guide.</p> </li> <li> <p>Gather inspiration    If you\u2019ve seen this feature in another tool or library, collect links or examples. Explaining what you like helps us assess fit quickly.</p> </li> </ol>"},{"location":"community/requesting-a-change/#issue-template","title":"Issue Template","text":"<p>When you\u2019re ready, open a new issue with the following sections:</p> <ul> <li>Title </li> <li>Context (optional) </li> <li>Description </li> <li>Related links </li> <li>Use cases </li> <li>Visuals (optional) </li> <li>Checklist</li> </ul>"},{"location":"community/requesting-a-change/#title","title":"Title","text":"<p>A concise, one\u2011sentence summary. Include keywords for easy search.</p> Example \u2714\ufe0f Clear \u201cAdd support for custom seed sampling strategies\u201d \u274c Unclear \u201cImprove sampling\u201d \u274c Useless \u201cFeature request\u201d"},{"location":"community/requesting-a-change/#context-optional","title":"Context (optional)","text":"<p>Brief environment or project details. For example:</p> <p>Using VerifIA v1.2.0 in a robotics QA workflow with domain YAML files defining kinematic constraints.</p> <p>Why</p> <p>Some features only make sense in specific contexts or use cases.</p>"},{"location":"community/requesting-a-change/#description","title":"Description","text":"<p>Explain what you propose, not why (use cases cover that). Be precise and concise.</p> <ul> <li>One idea per request.  </li> <li>Keep it to a few sentences.</li> </ul>"},{"location":"community/requesting-a-change/#related-links","title":"Related links","text":"<p>Link to any relevant issues, docs pages, or external examples. This helps us understand existing discussions or implementations.</p>"},{"location":"community/requesting-a-change/#use-cases","title":"Use cases","text":"<p>Describe how authors or users would leverage this change:</p> <ul> <li>Expected workflow impact  </li> <li>Who benefits and why  </li> <li>Potential backward\u2011compatibility concerns</li> </ul> <p>Why</p> <p>Clear use cases help us prioritize high\u2011value enhancements.</p>"},{"location":"community/requesting-a-change/#visuals-optional","title":"Visuals (optional)","text":"<p>Drop in mockups, diagrams, or screenshots if they clarify your idea. You can attach files or link to external assets.</p>"},{"location":"community/requesting-a-change/#checklist","title":"Checklist","text":"<p>Before submitting, confirm:</p> <ul> <li> I searched existing issues and docs  </li> <li> Title is clear and descriptive  </li> <li> Description precisely outlines the proposal  </li> <li> Related links provided  </li> <li> Use cases explained  </li> <li> Visuals attached (if applicable)  </li> </ul>"},{"location":"community/requesting-a-change/#rejected-requests","title":"Rejected Requests","text":"<p>If your request is declined, don\u2019t be discouraged! We balance many factors:</p> <ul> <li>Alignment with VerifIA\u2019s vision  </li> <li>Compatibility and maintenance effort  </li> <li>Benefit to the broader community  </li> <li>Simplicity and usability  </li> </ul> <p>Feel free to ask for clarification if you\u2019re unsure why a proposal wasn\u2019t accepted.  </p> <p>Thank you for helping shape VerifIA\u2019s future! \ud83c\udfaf  </p>"},{"location":"concepts/","title":"Core Concepts","text":"<p>VerifIA\u2019s verification pipeline is built around five key components. Each concept page dives into configuration and recommendations\u2014together they form the end\u2011to\u2011end workflow for domain\u2011aware model verification.</p> Concept Description Data How to provide and preprocess your original seed dataset, handle metadata, exclude out\u2011of\u2011domain or mispredicted examples, and balance seed diversity vs. runtime. Model Guidelines for preparing a model that\u2019s already optimized, validated, and tested\u2014wrapping it in the appropriate VerifIA API and understanding the role of domain\u2011aware checks. Domain Defining your application\u2019s a\u202fpriori knowledge\u2014variables, feasibility constraints , and behavioral rules\u2014in a compute\u2011friendly format. Searcher Configuring the population\u2011based, evolutionary search algorithms that probe each seed\u00d7rule subspace to surface behavioral inconsistencies. Run Orchestrating individual verification runs, sampling inputs, collecting per\u2011run metrics, and aggregating results into comprehensive reports."},{"location":"concepts/#workflow-overview","title":"Workflow Overview","text":"<ol> <li> <p>Prepare &amp; attach Data    Provide VerifIA with raw tabular data (files, DataFrame, or <code>Dataset</code>), validate metadata, and exclude seeds that are already mispredicted, or out of domain.</p> </li> <li> <p>Wrap &amp; attach Model    Use a built\u2011in <code>Model</code> wrapper or a pre-filled model\u2011card to load your optimized, tested model (scikit\u2011learn, CatBoost, XGBoost, TensorFlow, etc.) from a local disk or a model registry.</p> </li> <li> <p>Define your Domain    Encode variables, input constraints, and directional rules in YAML (or Python dict) so VerifIA knows how to derive and evaluate new test inputs.</p> </li> <li> <p>Select a Searcher    Choose and configure an evolutionary algorithm (e.g. GA, PSO, FFA) that will explore each constrained subspace for rule violations.</p> </li> <li> <p>Run Verification    Launch a <code>Run</code> with your budget (population size, iterations, optional seed sampling). Inspect per\u2011run metrics (consistency rate, violation counts, infeasible points) and aggregate across runs for final reporting.</p> </li> </ol> <p>Next Steps: - Dive into each concept page above to configure your pipeline. - Try a quick experiment with a tutorial or a use case.  - Follow the Domain Creation Guide to iterate on your domain creation.</p>"},{"location":"concepts/data/","title":"Data","text":"<p>VerifIA\u2019s verification pipeline is entirely data\u2011driven. The dataset you supply becomes the original seed from which VerifIA derives novel, out\u2011of\u2011sample inputs. Evaluating your model on these derived samples lets VerifIA measure its generalizability beyond the labeled data by verifying consistency with your application\u2019s domain knowledge.</p>"},{"location":"concepts/data/#1-seed-data","title":"1. Seed Data","text":"<ul> <li>The original seed is never evaluated \u201cas\u2011is.\u201d  </li> <li>It powers the generation of all verification inputs.  </li> <li>You may include:<ul> <li>Training data (examples already seen by the model)  </li> <li>Validation or test data (often yield more challenging derived inputs, since those regions tend to be less covered by the model)</li> </ul> </li> </ul> <p>VerifIA offers three ways to attach your seed data:</p> A. From Local FilesB. From pandas DataFrameC. Using VerifIA\u2019s Dataset Object <pre><code>from verifia.verification import RuleConsistencyVerifier\n\nverifier = RuleConsistencyVerifier(\"domain_rules.yaml\")\n# Supported formats: CSV, Excel, JSON, Parquet, Feather, Pickle\nverifier = verifier.on(data_fpath=\"path/to/data.csv\")\n</code></pre> Format Extension CSV <code>.csv</code> Excel <code>.xls</code>, <code>.xlsx</code> JSON <code>.json</code> Parquet <code>.parquet</code> Feather <code>.feather</code> Pickle <code>.pkl</code> <p>If your data comes from SQL, NoSQL, or APIs, load it into a DataFrame and pass it directly:</p> <pre><code>from verifia.verification import RuleConsistencyVerifier\nfrom your_code import load_my_data\n\nverifier = RuleConsistencyVerifier(\"domain_rules.yaml\")\ndf = load_my_data()  # e.g. pd.read_sql, API call, etc.\nverifier = verifier.on(dataframe=df)\n</code></pre> <p>To handle metadata (e.g., categorical features), wrap your DataFrame in <code>Dataset</code>:</p> <pre><code>from verifia.context.data import Dataset\nfrom verifia.verification import RuleConsistencyVerifier\n\n# 1. Load raw data\nimport pandas as pd\ndf = pd.read_csv(\"path/to/data.csv\")\n\n# 2. Define metadata\ntarget = \"predicted_label\"\nfeatures = [\"feat_1\", \"feat_2\", ...]\ncat_features = [\"cat_feat_1\", \"cat_feat_2\"]\n\n# 3. Create Dataset\nds = Dataset(df, target, features, cat_features)\n\n# 4. Initialize verifier and attach Dataset\nverifier = RuleConsistencyVerifier(\"domain_rules.yaml\")\nverifier = verifier.on(dataset=ds)\n</code></pre>"},{"location":"concepts/data/#2-derived-inputs","title":"2. Derived Inputs","text":"<p>VerifIA applies your configured search strategy (population size, iterations) and your defined domain (variables' ranges,constraints, and rules) to the original seed\u2014to explore new in\u2011domain datapoints. This approach probes beyond perfectly in\u2011distribution regions represented by labeled examples.</p>"},{"location":"concepts/data/#3-outofdomain-removal","title":"3. Out\u2011of\u2011Domain Removal","text":"<ol> <li>Validate each seed row against its feature metadata (ranges, types, constraints).  </li> <li>Remove rows with aberrant values (out\u2011of\u2011range, undefined) to prevent generation errors.  </li> <li>Report includes the count of removed out-of-domain seeds. </li> </ol> <p>Warning</p> <p>A high out\u2011of\u2011domain count can indicate:</p> <ul> <li>Noisy or invalid seed data  </li> <li>Incomplete or overly restrictive metadata  </li> </ul>"},{"location":"concepts/data/#4-misprediction-exclusion","title":"4. Misprediction Exclusion","text":"<p>To avoid biasing verification by known model errors, VerifIA excludes any seed row where the model already fails:</p> <ul> <li>Misclassification: predicted class\u00a0\u2260 ground truth  </li> <li>High Regression Error: |prediction\u00a0\u2013\u00a0ground truth|\u00a0&gt; allowed tolerance </li> </ul> <p>High Misprediction Rate</p> <ul> <li>Issue: A high number of exclusions signals that the model needs further optimization before advanced behavioral tests.  </li> <li>Action: Retrain or fine\u2011tune until mispredictions on validation/test examples drop to an acceptable level, then proceed with VerifIA's verifications.</li> </ul> <p>The report will show the count of excluded, mispredicted seeds.</p>"},{"location":"concepts/data/#5-seed-diversity","title":"5. Seed Diversity","text":"<ul> <li>A diverse, well\u2011dispersed seed lets VerifIA cover more of the input space.  </li> </ul> <p>Avoid sampling original seeds in narrow input space regions</p> <ul> <li>Visualize feature histograms, pairwise plots, or scatter plots to ensure broad coverage.  </li> <li>Perform unsupervised clustering (e.g., k\u2011means, DBSCAN) or compute pairwise distance metrics.  </li> </ul>"},{"location":"concepts/data/#6-verification-budget-runtime","title":"6. Verification Budget &amp; Runtime","text":"<ul> <li>Each seed row spawns many derived trials (population size\u00a0\u00d7 iterations\u00a0\u00d7 rules).  </li> <li>Adding seeds \u2260 linear runtime\u2014more seeds can dramatically increase run time.  </li> <li>Balance seed diversity against your compute budget; tune search parameters accordingly.</li> </ul> <p>Supported Data Types</p> <ul> <li>Current: Tabular data  </li> <li>Future: Images, natural\u2011language text, audio, and beyond  </li> </ul>"},{"location":"concepts/domain-genflow/","title":"Domain GenFlow","text":"<p>The Domain GenFlow component in VerifIA automates the creation of domain specifications\u2014variables, constraints,  and rules\u2014by harnessing Large Language Models (LLMs), multi-agent orchestration , and an interactive human\u2011in\u2011the\u2011loop (HITL) UI.  Instead of hand\u2011crafting YAML, you simply point DomainGenFlow at your data (CSV, DataFrame) and documentation (PDFs, vector database),  and it synthesizes a draft domain spec that you can review and refine, and validate through an integrated Gradio interface.</p> <p>Manually defining a Domain Specification involves:</p> <ul> <li>Enumerating feature variables with types, ranges, and descriptions  </li> <li>Writing constraints that all data must satisfy  </li> <li>Crafting rules that describe logical relationships between inputs and the target  </li> </ul> <p>Manual Effort &amp; Risk</p> <p>As model complexity and business rules evolve, manual specification is error\u2011prone and time\u2011intensive.</p> <p>Domain GenFlow standardizes and accelerates this process by orchestrating LLM\u2011powered agents, while keeping you in control via a simple UI.</p>"},{"location":"concepts/domain-genflow/#1-domain-specification","title":"1. Domain Specification","text":"<p>A Domain Specification codifies how a model should behave within a particular context. It comprises three core elements:</p> <ul> <li>Variables: Input features with types (e.g., numerical, categorical), permissible ranges or categories, and descriptions.</li> <li>Constraints: Conditions that all data points must satisfy (e.g., <code>age &gt;= 0</code>, <code>balance &gt; 0</code>).</li> <li>Rules: Logical relationships describing how inputs influence the target (premises \u2192 conclusion).</li> </ul> <p>This specification guides verification by clearly defining the expected behavior of the model under various conditions.</p>"},{"location":"concepts/domain-genflow/#2-core-components-llmpowered-agents","title":"2. Core Components: LLM\u2011Powered Agents","text":"<p>VerifIA's Domain GenFlow employs two specialized agent types, each powered by LLMs via LangChain:</p> <p>2.1. DataFrame Analysis Agents: extends LangChain's pandas DataFrame agent to:</p> <ul> <li> <p>Automatically detect feature types (categorical, numerical).</p> </li> <li> <p>Identify statistical properties (min, max, value ranges).</p> </li> <li> <p>Infer data-driven constraints and domain rules relevant for model verification.</p> </li> </ul> <p>2.2. Retriever Agents: Search external documents (e.g., PDF reports) to:</p> <ul> <li> <p>extract domain knowledge from unstructured documentation.</p> </li> <li> <p>Identify explicit constraints and domain rules described in documents.</p> </li> <li> <p>Provide rich textual descriptions of features and target variables.</p> </li> </ul> <p>Goal</p> <p>These agents collaboratively operate in a graph-based workflow powered by LangGraph, merging insights from  structured data and unstructured domain documentation into a cohesive domain specification.</p>"},{"location":"concepts/domain-genflow/#3-orchestration-via-stategraph","title":"3. Orchestration via StateGraph","text":"<p>The AI-based Domain Generation feature is orchestrated via a LangGraph StateGraph, which manages the workflow as follows:</p> <ol> <li>Parallel Branches: DataFrame and Retriever agents run concurrently for variables, constraints, and rules.</li> <li>YAML Generation Node: Merges agent outputs into a draft specification in JSON/YAML format.</li> <li>Human\u2011In\u2011The\u2011Loop (HITL) Interaction Node: Pauses execution, exposing the draft YAML and validator output for user edits or instructions. 4Validation Node: Parses the draft against a Pydantic schema and runs rule-consistency checks. On validation errors,  control returns to HITL node for retry or regeneration. On success, the graph reaches <code>END</code>.</li> </ol> LangGraph Visualization <pre><code>---\nconfig:\n  flowchart:\n    curve: linear\n---\ngraph TD;\n    __start__([&lt;p&gt;__start__&lt;/p&gt;]):::first\n    analyser_variables(analyser_variables)\n    retriever_variables(retriever_variables)\n    analyser_constraints(analyser_constraints)\n    retriever_constraints(retriever_constraints)\n    analyser_rules(analyser_rules)\n    retriever_rules(retriever_rules)\n    yaml_generator(yaml_generator)\n    human_interaction(human_interaction)\n    yaml_validator(yaml_validator)\n    __end__([&lt;p&gt;__end__&lt;/p&gt;]):::last\n    __start__ --&gt; analyser_constraints;\n    __start__ --&gt; analyser_rules;\n    __start__ --&gt; analyser_variables;\n    __start__ --&gt; retriever_constraints;\n    __start__ --&gt; retriever_rules;\n    __start__ --&gt; retriever_variables;\n    analyser_variables -.-&gt; yaml_generator;\n    retriever_variables -.-&gt; yaml_generator;\n    analyser_constraints -.-&gt; yaml_generator;\n    retriever_constraints -.-&gt; yaml_generator;\n    analyser_rules -.-&gt; yaml_generator;\n    retriever_rules -.-&gt; yaml_generator;\n    yaml_generator -.-&gt; human_interaction;\n    human_interaction -.-&gt; yaml_generator;\n    human_interaction -.-&gt; yaml_validator;\n    human_interaction -.-&gt; __end__;\n    yaml_validator -.-&gt; human_interaction;\n    classDef default fill:#f2f0ff,line-height:1.2\n    classDef first fill-opacity:0\n    classDef last fill:#bfb6fc</code></pre>"},{"location":"concepts/domain-genflow/#4-usage-workflow","title":"4. Usage Workflow","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Idle\n    Idle --&gt; Loading: load_ctx()\n    Loading --&gt; Generating: start()\n    Generating --&gt; HumanInteraction: yaml_generator\n    HumanInteraction --&gt; Validating: validate\n    Validating --&gt; HumanInteraction: validation_output\n    HumanInteraction --&gt; Generating: regenerate\n    HumanInteraction --&gt; Completed: finish</code></pre> <ol> <li>Context Loading <ul> <li>Read CSV or DataFrame  </li> <li>Build or load Chroma vector store from PDFs or text  </li> <li>Load model\u2011card metadata  </li> </ul> </li> <li>Graph Construction <ul> <li>Register analysis + retrieval nodes in a StateGraph  </li> </ul> </li> <li>Execution <ul> <li>Invoke graph: agents run, outputs accumulate in <code>DomainGraphState</code> </li> <li>YAML generator merges insights into an initial draft YAML</li> <li>HumanInteraction Node (via The Gradio UI) displays draft YAML</li> <li>You can Validate, Regenerate with custom instructions, or Finish.</li> <li>Validator checks schema and rule consistency</li> </ul> </li> <li> <p>Output </p> <p>Automated Domain Spec</p> <p>On success, you receive a ready\u2011to\u2011use YAML file with full domain definitions.</p> <p>Automated Domain Spec</p> <p>On failure, loops back to interactive review until resolved</p> </li> </ol>"},{"location":"concepts/domain-genflow/#5-interactive-gradio-ui","title":"5. Interactive Gradio UI","text":"<p>The Gradio UI component consists of:</p> <ul> <li> <p>YAML Specification Panel: An interactive code view showing the current draft of the YAML spec.</p> </li> <li> <p>Instructions Box: A textbox where you can enter custom instructions for regeneration.</p> </li> <li> <p>Validation Output: Displays schema and consistency check messages.</p> </li> <li> <p>Action Buttons:</p> <ul> <li>\ud83d\ude80 Start Generation: Kick off the domain spec generation.</li> <li>\u2705 Validate: Run the validator on the current YAML.</li> <li>\ud83d\udd04 Regenerate: Regenerate the YAML with your custom instructions.</li> <li>\ud83c\udf89 Finish: Complete the process and produce the final spec.</li> </ul> </li> </ul> <p>Use this interface to iteratively refine and finalize your domain specification.</p>"},{"location":"concepts/domain-genflow/#6-yaml-specification-format","title":"6. YAML Specification Format","text":"<p>The final output from AI-based domain generation is structured as a YAML Specification:</p> <p>example of a YAML Specification</p> <pre><code>variables:\n  age:\n    description: \"Age of the applicant\"\n    type: INT\n    range: [18, 65]\nconstraints:\n  positive_balance:\n    description: \"Account balance must always be positive\"\n    formula: \"account_balance &gt; 0\"\nrules:\n  credit_risk_rule:\n    description: \"Higher debt-to-income ratio increases credit risk\"\n    premises:\n      debt_income_ratio: inc\n    conclusion:\n      credit_risk: inc\n</code></pre>"},{"location":"concepts/domain-genflow/#7-next-steps-pointers","title":"7. Next Steps / Pointers","text":"<ul> <li>Review and refine the generated YAML using the UI.   </li> <li>Integrate <code>domain_spec.yaml</code> into your VerifIA verification pipeline.  </li> <li>Provide feedback on edge\u2011case handling and retriever performance.</li> </ul>"},{"location":"concepts/domain-genflow/#8-humanai-collaboration-error-handling","title":"8. Human\u2011AI Collaboration &amp; Error Handling","text":"<p>While AI automates much of the specification process, human review remains essential:</p> <ul> <li>Validation Errors: Fix YAML syntax or schema mismatches via UI instructions.  </li> <li>Logical Consistency: Ensure rules accurately reflect domain knowledge.  </li> <li>Iterative Tuning: Adjust prompts, model settings, or input data and retry.  </li> </ul> <p>Human\u2011AI Collaboration</p> <p>Your domain expertise combined with AI efficiency yields reliable, production\u2011ready specifications.</p>"},{"location":"concepts/domain/","title":"Domain","text":"<p>VerifIA is a domain\u2011aware verification tool that assesses a predictive model\u2019s consistency with your application\u2019s domain knowledge. Instead of verifying only on existing labeled examples, VerifIA derives novel inputs from your seed dataset\u2014expanding input\u2011space coverage and building confidence that the model will behave correctly under real\u2011world, future conditions.</p>"},{"location":"concepts/domain/#1-initializing-the-verifiers-domain","title":"1. Initializing the Verifier\u2019s Domain","text":"<p>VerifIA\u2019s <code>RuleConsistencyVerifier</code> requires your domain configuration up front. To create yours, Follow the detailed guidelines in Domain Creation Guide. Once it is done, Supply it either as a YAML file path or as an in\u2011memory dictionary:</p> A. From YAML FileB. From Python Dictionary <pre><code>from verifia.verification import RuleConsistencyVerifier\n\n# Load rules from a domain YAML file\nverifier = RuleConsistencyVerifier(\"path/to/domain_rules.yaml\")\n</code></pre> <pre><code>from verifia.verification import RuleConsistencyVerifier\n\n# Define your domain config in code\ndomain_cfg = {\n  \"variables\":    { \u2026 },\n  \"constraints\":  { \u2026 },\n  \"rules\":        { \u2026 }\n}\n\n# Instantiate verifier directly from dict\nverifier = RuleConsistencyVerifier(domain_cfg)\n</code></pre>"},{"location":"concepts/domain/#2-application-domain-knowledge","title":"2. Application Domain Knowledge","text":"<p>Your domain knowledge includes all the a\u202fpriori information you possess about your application\u2014particularly expectations around how your input (and output) variables are distributed.</p> <ul> <li>Documented rules or formulas </li> <li>Simulator logic in legacy systems  </li> <li>Expert heuristics and common\u2011sense insights  </li> </ul> <p>Note</p> <p>You gather the domain knowledge; VerifIA then helps you summarize it into a compute\u2011friendly format and leverages it to generate and validate novel test cases.</p>"},{"location":"concepts/domain/#3-domain-variables","title":"3. Domain Variables","text":"<p>VerifIA works on raw features and outputs\u2014no preprocessing or feature engineering required. </p> <p>For each variable you must specify:</p>"},{"location":"concepts/domain/#31-definition","title":"3.1. Definition","text":"<ul> <li>Type: <code>INT</code>, <code>FLOAT</code>, or <code>CAT</code> </li> <li>Domain: <ul> <li>Numeric \u2192 <code>[min, max]</code> range  </li> <li>Categorical \u2192 list of allowed values (order matters if ordinal)  </li> </ul> </li> <li>Computed formula (optional): derive one variable from others  </li> </ul> <p>All definitions use real\u2011world scales so that derived inputs remain plausible.</p> <p>To expose model brittleness, VerifIA perturbs inputs within two configurable thresholds:</p>"},{"location":"concepts/domain/#32-variation-limits","title":"3.2. Variation limits","text":"<ul> <li>Range: <code>[min_ratio, max_ratio]</code> <ul> <li>min_ratio ensures changes are large enough to trigger detectable effects  </li> <li>max_ratio prevents unrealistic drift from the original seed </li> </ul> </li> </ul> <p>Tip</p> <p>Adjust <code>max_ratio</code> higher for robustness testing, lower for strict domain consistency.</p>"},{"location":"concepts/domain/#33-insignificant-variation","title":"3.3. Insignificant variation","text":"<ul> <li>Ratio within (<code>0.0\u20131.0</code>)  <ul> <li>Inputs: injects white\u2011noise to reveal fragile decision nonlinear boundaries</li> <li>Outputs: defines acceptable prediction error when evaluating regression targets  </li> </ul> </li> </ul> <p>Example</p> <p>A 1% noise on a float input can uncover hidden biases where minor input shifts cause outsized output changes.</p>"},{"location":"concepts/domain/#4-feasibility-constraints","title":"4. Feasibility Constraints","text":"<p>Individual variable ranges do not capture interdependencies. Constraints are mathematical conditions over multiple variables. VerifIA uses them to define and enforce the feasible input space:</p> <ul> <li>Express relationships such as \u201c<code>feature_A + feature_B &lt;= 100</code>\u201d  </li> <li>Discard any derived datapoint violating these formulas  </li> </ul> <p>Insight</p> <p>Well\u2011defined constraints prevent generation of impossible or semantically-invalid inputs.</p>"},{"location":"concepts/domain/#5-behavioral-rules","title":"5. Behavioral Rules","text":"<p>The core of domain verification lies in rules that assert how the model\u2019s output should respond when inputs change:</p> <ul> <li>Premises: describe input variations (<code>increase</code>, <code>decrease</code>, <code>stall</code>, or categorical conditions: <code>equal</code>, <code>in</code>, etc.)  </li> <li>Conclusions: assert output direction (<code>increase</code>, <code>decrease</code>, <code>stall</code>) or allowed stability (<code>no increase</code>, <code>no decrease</code>)  </li> </ul> <p>VerifIA uses these rules to:</p> <ol> <li>Derive new inputs consistent with domain space and constraints  </li> <li>Compute expected output behavior without needing groundtruth labels  </li> </ol> <p>Insight</p> <p>Unlike statistical tests, you do not need to know exact target values for the novel inputs\u2014rules express relative expectations (e.g., \u201cif price goes up, demand should go down\u201d).</p> <ul> <li>No ground\u2011truth targets required for derived inputs</li> <li>Seed validation: original seeds must be in-domain and correctly handled by the model</li> <li>Consistency\u2011Only Verification: complements standard statistical evaluation (accuracy, RMSE) by ensuring domain\u2011level consistency beyond IID assumptions  </li> </ul> <p>Tips</p> <ul> <li>Balance variation: too little change hides problems; too much change explores unrealistic scenarios.  </li> <li>Iterate: refine rules and constraints based on initial findings to target subtle behavioral gaps.</li> </ul>"},{"location":"concepts/domain/#6-guided-subspace-exploration","title":"6. Guided Subspace Exploration","text":"<p>Applying every rule to every seed row defines a constrained subspace of potential inputs. </p> <p>Exhaustive enumeration is unpractical, so VerifIA employs population\u2011based metaheuristics to reveal inconsistencies in model behavior regardless of how rare they may be.</p> <p>Be Careful</p> <ul> <li>Tune the run parameters (population size, max iterations) to balance discovery power against compute budget.</li> <li>Poorly-defined rules or constraints can lead to false positives or missed inconsistencies.  </li> </ul>"},{"location":"concepts/model/","title":"Model","text":"<p>VerifIA performs a domain\u2011aware verification on a model that has already passed all standard evaluation steps, as described in the following pre\u2011Verification requirements. </p> <p>Your model must be:</p> <ul> <li> <p>Optimized </p> <ul> <li>Model parameters are carefully trained and fine-tuned.</li> </ul> </li> <li> <p>Validated </p> <ul> <li>All modeling decisions are evaluated on a validation set (e.g., hyperparameters).</li> </ul> </li> <li> <p>Tested </p> <ul> <li>Performance is assessed on unseen test sets, used as a proxy for future data.</li> </ul> </li> </ul> <p>Success</p> <p>Only once these evaluation steps yield satisfactory results should you run VerifIA\u2019s domain\u2011aware verification.</p>"},{"location":"concepts/model/#1-staging-model-setup","title":"1. Staging Model Setup","text":""},{"location":"concepts/model/#11-build-the-wrapper","title":"1.1 Build the Wrapper","text":"<p>Select the appropriate wrapper or use a model card helper:</p> A. Direct InstantiationB. From Model Card <pre><code>from verifia.models import SKLearnModel, build_from_model_card\n\n# Example metadata\nfeature_names = [\"feat_1\", \"feat_2\"]\ntarget_name = \"predicted_label\"\ncat_features = [\"cat_feat_1\"]\n\nmodel_wrapper = SKLearnModel(\n    name=\"my_model\",\n    version=\"1\",\n    model_type=\"regression\",\n    feature_names=feature_names,\n    target_name=target_name,\n    local_dirpath=\"./models\",\n    cat_feature_names=cat_features\n)\n</code></pre> <pre><code>from verifia.models import SKLearnModel, build_from_model_card\n\n# Example metadata\nfeature_names = [\"feat_1\", \"feat_2\"]\ntarget_name = \"predicted_label\"\ncat_features = [\"cat_feat_1\"]\n\nmodel_card = {\n\"name\": \"skl_model\",\n\"version\": \"1\",\n\"type\": \"regression\",\n\"framework\": \"sklearn\",\n\"feature_names\": feature_names,\n\"target_name\": target_name,\n\"cat_feature_names\": cat_features,\n\"local_dirpath\": \"./models\"\n}\nmodel_wrapper = build_from_model_card(model_card)\n</code></pre> <p>Supported frameworks: sklearn, lightgbm, catboost, xgboost, pytorch, tensorflow.</p>"},{"location":"concepts/model/#12-load-the-model","title":"1.2 Load the Model","text":"A. Wrap an in-memory objectB. Load from local fileC. Load from registry <pre><code>model_obj = ...  # optimized model object\nmodel_wrapper.wrap_model(model_obj)\n</code></pre> <pre><code># If file path is None, VerifIA uses default: {name}-{version}.{ext}\nmodel_wrapper.load_model(model_fpath=None)\n</code></pre> <p>Default extensions: pkl, txt, cb, json, pth, keras.</p> <pre><code># After setting platform env vars\nmodel_wrapper.load_model_from_registry()\n</code></pre> <p>Supported platforms: MLflow, Comet ML, WandB.</p>"},{"location":"concepts/model/#13-attach-model-to-verifier","title":"1.3. Attach Model to Verifier","text":"<pre><code>from verifia.verification import RuleConsistencyVerifier\nverifier = RuleConsistencyVerifier(\"domain_rules.yaml\")\nverifier = verifier.verify(model=model_wrapper)\n</code></pre> Auto-load <p>You may also skip manual loading:</p> <pre><code># Pass model card directly\nverifier = verifier.verify(model_card=model_card)\n</code></pre> <p>VerifIA auto-loads from registry or local if needed.</p>"},{"location":"concepts/model/#2-statistical-evaluation-caveats","title":"2. Statistical Evaluation Caveats","text":"<p>Standard metrics (accuracy, RMSE, F1, etc.) depend heavily on your data\u2019s:</p> <ul> <li> <p>Correctness </p> <ul> <li>Low noise, high precision  </li> </ul> </li> <li> <p>Coverage </p> <ul> <li>Diverse, comprehensive sampling of the input distribution  </li> </ul> </li> </ul> <p>Trade-off</p> <p>Achieving both can be challenging in real\u2011world settings.</p>"},{"location":"concepts/model/#3-why-domainaware-verification","title":"3. Why Domain\u2011Aware Verification?","text":"<p>Traditional statistical evaluation assumes:</p> <ol> <li>IID inputs </li> <li>Representative test data covering all foreseeable cases  </li> </ol> <p>VerifIA goes beyond these assumptions by:</p> <ul> <li>Generating novel, out\u2011of\u2011sample inputs </li> <li>Verifying model behavior against application\u2011specific domain knowledge </li> <li>Maximizing coverage of the model\u2019s input space</li> </ul> <p>Expanded coverage</p> <p>VerifIA helps explore regions of the input space that training and test sets may miss.  </p> <p>Behavior consistency</p> <p>Domain rules expose inconsistencies, alerting you to harmful noise or bias in training data. </p> <p>Original Seed Quality</p> <p>VerifIA still relies on your original seed data to derive new test cases. Poor data quality or insufficient coverage can lead to misleading or unreliable verification results.  </p>"},{"location":"concepts/run/","title":"Run","text":"<p>A run is a single VerifIA execution over your domain rules that searches for behavioral inconsistencies of your model using a selected original seeds. It is the building block of a full verification report that can be saved in HTML report. </p> <p>Each verification report is scoped to a specific model version and a defined domain, yet it aggregates all runs\u2014across different seed subsets and search algorithms\u2014to build cumulative evidence of the model\u2019s consistency within that domain.</p>"},{"location":"concepts/run/#1-run-configuration","title":"1. Run Configuration","text":"<p>Each run is parameterized by:</p> <ul> <li>Population size (<code>pop_size</code>): number of candidate inputs per generation. Check searcher's run-wise parameters.</li> <li>Max iterations (<code>max_iters</code>): evolutionary budget per seed\u2013rule subspace. Check searcher's run-wise parameters.  </li> <li>Sampling strategy (<code>orig_seed_ratio</code> or <code>orig_seed_size</code>): randomly select a subset of seed inputs instead of using the full dataset.</li> </ul> <p>Purpose of Sampling</p> <ul> <li>Fast trials: shorter runtimes to validate domain metadata and hyperparameters by quick \u201csmoke tests\u201d. </li> <li>Variance analysis: run multiple samples to gauge how seed diversity impacts consistency metrics</li> <li>Configuration tuning: iterate on population/iteration settings without full\u2011data cost</li> </ul>"},{"location":"concepts/run/#2-verification-result","title":"2. Verification Result","text":"<p>VerifIA can persist the outcomes of multiple runs into a single, consolidated report\u2014tracking both per\u2011run details and aggregated metrics.</p>"},{"location":"concepts/run/#21-runlevel-metrics","title":"2.1 Run\u2011Level Metrics","text":"<p>Each individual run records:</p> <ul> <li> <p>Parameters /</p> </li> <li> <p>Searcher</p> <ul> <li>Algorithm name (e.g. GA, PSO)</li> <li>Algorithm parameters</li> </ul> </li> <li> <p>Run Statistics</p> <ul> <li>Seed rows evaluated</li> <li>Total rules applied</li> <li>Total derived verifications</li> <li>Out\u2011of\u2011domain exclusions</li> <li>Seed mispredictions</li> </ul> </li> <li> <p>Performance Metrics</p> <ul> <li>Consistency rate (overall / per rule): fraction of derived inputs satisfying all rules</li> <li>Compliance rate (overall / per rule): fraction satisfying all constraints</li> <li>Violation count (overall / per rule): number of derived inputs breaking \u2265\u202f1 rule</li> <li>Infeasible count (overall / per rule): derived points discarded by constraints</li> <li>Inconsistency\u2011revealing seed count (overall / per rule): seeds that generated at least one violating input</li> <li>Average deviation per rule: mean magnitude by which predictions diverged from expected behavior</li> </ul> </li> </ul>"},{"location":"concepts/run/#22-reportlevel-metrics","title":"2.2 Report\u2011Level Metrics","text":"<p>The consolidated report aggregates across runs to provide:</p> <ul> <li> <p>Model Metadata</p> <ul> <li>Name, version, framework</li> </ul> </li> <li> <p>Aggregate Statistics</p> <ul> <li>Total seed size</li> <li>Total rules</li> <li>Total verifications</li> <li>Out\u2011of\u2011domain rate</li> <li>Seed misprediction rate</li> </ul> </li> <li> <p>Domain Compliance</p> <ul> <li>Violated rules and overall rules consistency ratio</li> <li>Unsatisfied constraints and overall constraints compliance ratio</li> <li>Frequency of inconsistency\u2011revealing seeds</li> </ul> </li> </ul> <p>Insight</p> <p>High consistency with low deviation indicates strong domain alignment. Low consistency or high deviation highlights model weaknesses or gaps in domain definitions.</p>"},{"location":"concepts/run/#5-aggregating-incremental-domains","title":"5. Aggregating &amp; Incremental Domains","text":"<ul> <li>Multiple runs can vary in seed subsets, algorithms, or parameters\u2014compare side by side.</li> <li> <p>Domain evolution:</p> <ul> <li>Adding new rules/constraints is safe\u2014new runs simply include them.</li> <li>Removing existing rules/constraints invalidates prior aggregates.</li> </ul> </li> </ul> <p>Best Practice</p> <p>If you must modify the domain (especially by dropping elements), archive and clear previous report data before re\u2011running to ensure coherent aggregation.</p>"},{"location":"concepts/run/#6-running-the-verification","title":"6. Running the Verification","text":"<p>Once you have your domain, model, data, and searcher configured, launch the rule\u2011consistency check:</p> <pre><code>from verifia.verification import RuleConsistencyVerifier\nfrom verifia.verification.results import RulesViolationResult\n\n# 1. Prepare your wrapped model and test data\nmodel_wrapper = ...        # e.g. SKLearnModel, CBModel, etc.\ntest_dataframe = ...       # pandas DataFrame of your test or validation set\n\n# 2. Initialize the verifier with your domain config\nverifier = RuleConsistencyVerifier(\"path/to/domain_rules.yaml\")\n\n# 3. Attach the model and data, select search algorithm\nverifier = (\n    verifier\n    .verify(model_wrapper)                 # Model under test\n    .on(test_dataframe)                    # Seed data source\n    .using(\"PSO\", search_params={          # Choose searcher and its params\n        \"c_1\": 1.0,\n        \"c_2\": 1.0,\n        \"w_max\": 0.9,\n        \"w_min\": 0.4\n    })\n)\n\n# 4. Run with your verification budget\nresult: RulesViolationResult = verifier.run(\n    pop_size=100,      # candidates per generation\n    max_iters=10,      # total number of generations\n    orig_seed_ratio=0.5  # optional: use 50% of seed samples\n)\n\n# 5. Generate an HTML report\nresult.save_as_html(\"model_verification_report.html\")\n\n# tip: clean up the result if you remove/edit rules\nverifier.clean_results()\n</code></pre> Controlling the Seed Sample <ul> <li> <p><code>orig_seed_ratio</code> (<code>float</code>, optional)</p> <ul> <li>The fraction of your original seed rows to inject into each generation.</li> <li>Example: <code>orig_seed_ratio=0.5</code> uses 50% of the DataFrame rows each iteration.</li> </ul> </li> <li> <p><code>orig_seed_size</code> (<code>int</code>, optional)</p> <ul> <li>The absolute number of seed rows to include.</li> <li>Example: <code>orig_seed_size=200</code> always seeds each generation with 200 original samples.</li> </ul> </li> </ul> <p>Note: Only one of <code>orig_seed_ratio</code> or <code>orig_seed_size</code> should be set. If both are provided, <code>orig_seed_size</code> takes precedence. By default, 100% of the seed data is used (<code>orig_seed_ratio=1.0</code>).</p> Setting Reporting Config <p>You can customize where VerifIA stores checkpointed reports and how many decimal places are shown in metrics via environment variables:</p> <pre><code>export VERIFIA_CHECKPOINTS_DIRPATH=\"/path/to/checkpoints\"\nexport VERIFIA_ROUNDING_PRECISION=4\n</code></pre> <ul> <li> <p><code>VERIFIA_CHECKPOINTS_DIRPATH</code></p> <ul> <li>Default: <code>.verifia/</code></li> <li>Directory where run checkpoints and reports are saved.</li> </ul> </li> <li> <p><code>VERIFIA_ROUNDING_PRECISION</code></p> <ul> <li>Default: <code>2</code></li> <li>Number of decimal places used when rounding and displaying reported metrics.</li> </ul> </li> </ul>"},{"location":"concepts/searcher/","title":"Searcher","text":"<p>The Searcher is a core VerifIA component that explores the input subspace defined by each original\u2011seed\u00a0\u00d7\u00a0rule pair. It uses population\u2011based evolutionary algorithms to both discover challenging derived inputs and quantify overall consistency.</p>"},{"location":"concepts/searcher/#1-objective-function","title":"1. Objective Function","text":"<ul> <li>Goal: Find derived inputs that maximize deviation between the model\u2019s prediction and the rule\u2011based expected response.  </li> <li>Why not a single optimum? A single \u201cworst\u201d violation doesn\u2019t prove inconsistency. Instead, multiple inconsistent points must be observed to statistically reject a model.</li> </ul>"},{"location":"concepts/searcher/#2-statistical-consistency-measurement","title":"2. Statistical Consistency Measurement","text":"<ol> <li>Population of derived inputs <ul> <li>Initialize a set of candidate points within the constrained subspace.  </li> </ul> </li> <li>Evolutionary optimization <ul> <li>Evolve the population to increase prediction deviation from the expected output direction (e.g. if rule says \u201coutput\u00a0\u2191\u201d, seek predictions with stalled or decreased values).  </li> </ul> </li> <li>Consistency ratio <ul> <li>For each seed\u2011rule pair, compute the fraction of derived inputs that violate the rule.  </li> <li>Aggregate ratios across all seeds and rules to measure model consistency against the full domain.</li> </ul> </li> </ol>"},{"location":"concepts/searcher/#3-populationbased-evolutionary-algorithms","title":"3. Population\u2011Based Evolutionary Algorithms","text":"<p>VerifIA currently supports several nature\u2011inspired population-based evolutionary metaheuristics:</p> Algorithm Enum Key Description Random Sampler <code>RS</code> Fresh random sampling each iteration. Firefly Algorithm <code>FFA</code> Bioluminescent attraction &amp; random moves.  params: <code>beta_min</code>, <code>gamma</code>, <code>alpha</code>, <code>theta</code> Genetic Algorithm <code>GA</code> Crossover &amp; mutation on elites/parents.  params: <code>mutation_prob</code>, <code>crossover_prob</code>, <code>elite_ratio</code> Particle Swarm <code>PSO</code> Velocity &amp; position updates via personal/global best.  params: <code>c_1</code>, <code>c_2</code>, <code>w_max</code>, <code>w_min</code>. Grey Wolf Optimizer <code>GWO</code> Leadership hierarchy &amp; encircling prey principles. Moth\u2013Flame Optimizer <code>MFO</code> Spiral movement around ranked \u201cflames\u201d.  params: <code>b</code> Multi\u2011Verse Optimizer <code>MVO</code> Universe inflation/deflation &amp; wormhole tunneling.  params: <code>WEP_min</code>, <code>WEP_max</code>, <code>TDR_p</code>. Salp Swarm Algorithm <code>SSA</code> Chain\u2011structured population with leader &amp; followers. Whale Optimization <code>WOA</code> Encircling &amp; spiral bubble-net attacks.  params: <code>b</code> <p>The algorithm\u2011specific <code>params</code> control exploration/exploitation balance.</p>"},{"location":"concepts/searcher/#4-run-wise-configurable-parameters","title":"4. Run-wise Configurable Parameters","text":"<p>All population-based searching algorithms accept these two parameters at runtime:</p> Parameter Purpose Default <code>pop_size</code> Number of candidates per generation user\u2011defined <code>max_iters</code> Iteration budget user\u2011defined <p>Tune <code>pop_size</code> &amp; <code>max_iters</code> to trade off coverage/search scope vs runtime/compute budget. </p>"},{"location":"concepts/searcher/#5-workflow-summary","title":"5. Workflow Summary","text":"<ol> <li> <p>For each original seed\u00a0\u00d7\u00a0rule pair:    a. Define the constrained subspace (white-noise\u00a0+\u00a0variation limits + constraints).    b. Initialize a random population within that subspace.    c. Evolve the population using the selected algorithm and objective function.    d. Collect derived inputs that violate the rule.  </p> </li> <li> <p>Compute consistency ratios:  </p> <ul> <li><code>ratio = violations_count / total_candidates</code> </li> </ul> </li> <li> <p>Aggregate across all rules and seeds to assess overall domain consistency.</p> </li> </ol>"},{"location":"concepts/searcher/#6-selecting-your-searcher","title":"6. Selecting your Searcher","text":"<p>Before running verification, you must seect which searcher VerifIA will use and its parameters:</p> <pre><code>from verifia.verification import RuleConsistencyVerifier\n\nverifier = RuleConsistencyVerifier(\"domain_rules.yaml\")\n\n# Provide algorithm name and optional parameters\nverifier = verifier.using(\n    search_algo=\"PSO\",\n    search_params={\n        \"c_1\": 0.5,    # lower personal influence\n        \"c_2\": 0.3,    # higher social influence\n        \"w_max\": 0.8,  # reduced max inertia\n        \"w_min\": 0.2   # increased exploitation\n    }\n)\n</code></pre> <p>Failure</p> <p>Do not include <code>pop_size</code> or <code>max_iters</code> in <code>search_params</code>; they belong in the top\u2011level <code>.run()</code> call.</p>"},{"location":"guides/ai-for-domain-generation/","title":"Generating a Domain YAML File using AI","text":"<p>This guide shows you how to use AI-powered VerifIA feature, Domain Genflow that generates the domain specification  Instead of manually crafting it as described in Domain Creation.  For a deeper conceptual overview of Domain Genflow in VerifIA, see Concepts \u2192 Domain Genflow.</p>"},{"location":"guides/ai-for-domain-generation/#why-using-ai-for-domain-generation","title":"Why Using AI for Domain Generation?","text":"<p>Crafting a Domain Specification manually means:</p> <ul> <li>Enumerating feature variables with types, ranges, and descriptions</li> <li>Writing constraints that all inputs must satisfy</li> <li>Defining rules that express logical relationships between inputs and the target</li> </ul> <p>As your models and business logic grow more complex, this process becomes time\u2011consuming, error\u2011prone, and hard to maintain.</p> <p>Solution: VerifIA automates and orchestrates LLM\u2011powered agents to extract domain knowledge from both structured (DataFrame) and unstructured (PDF, Markdown) sources, delivering:</p> <ul> <li>Efficiency: Free your team from tedious YAML editing.</li> <li>Accuracy: Leverage AI\u2019s pattern recognition to reduce human inconsistency.</li> <li>Scalability: Reuse the workflow across diverse datasets and domains.</li> </ul>"},{"location":"guides/ai-for-domain-generation/#feature-overview","title":"Feature Overview","text":"<pre><code>%%{init:{\n  'flowchart': {\n    'useMaxWidth': true,\n    'nodeSpacing': 50,\n    'rankSpacing': 22\n  }\n}}%%\nflowchart LR\n  %%\u2014\u2014 Subgraphs for each layer \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n  subgraph InputLayer[\ud83d\udce5 **Input Layer**]\n    direction LR\n    A[\ud83d\uddc2\ufe0f&lt;br/&gt;Data]\n    C[\ud83d\udccb&lt;br/&gt;Model&lt;br/&gt;Card]\n    B[\ud83d\udcc4&lt;br/&gt;Docs]\n  end\n\n  subgraph AgentLayer[\ud83e\udd16 **Agent Layer**]\n    direction LR\n    D[\ud83d\udc3c&lt;br/&gt;DataFrame&lt;br/&gt;Agents]\n    E[\ud83d\udcd6&lt;br/&gt;Retriever&lt;br/&gt;Agents]\n  end\n\n  subgraph CoreLayer[\u2699\ufe0f **Core**]\n    direction LR\n    F[\ud83d\udee0\ufe0f&lt;br/&gt;State&lt;br/&gt;Graph]\n  end\n\n  subgraph GenValLayer[\ud83d\udd04 **Generation &amp; Validation**]\n    direction LR\n    G[\ud83d\udcdd&lt;br/&gt;YAML&lt;br/&gt;Generator]\n    J[\ud83e\udd1d&lt;br/&gt;**Human**&lt;br/&gt;**UI**]\n    H[\ud83d\udd0d&lt;br/&gt;Schema&lt;br/&gt;Validator]\n  end\n\n  subgraph ExportLayer[\ud83d\udce4 **Export**]\n    direction LR\n    I[\ud83d\udce6&lt;br/&gt;Domain&lt;br/&gt;Spec]\n  end\n\n  %%\u2014\u2014 Arrows between layers \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n  A --&gt; D\n  B --&gt; E\n  C --&gt; D\n  C --&gt; E\n\n  D --&gt; F\n  E --&gt; F\n\n  F --&gt; G\n  G --&gt; J\n  J --&gt; H\n  H --&gt; J\n  J --&gt; G\n  J --&gt; I\n\n  %%\u2014\u2014 Style each subgraph background \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 \n  style InputLayer   fill:#f9f9f9,stroke:#333,stroke-width:1px\n  style AgentLayer   fill:#eef9ff,stroke:#333,stroke-width:1px\n  style CoreLayer    fill:#f9fef2,stroke:#333,stroke-width:1px\n  style GenValLayer  fill:#fff8f2,stroke:#333,stroke-width:1px\n  style ExportLayer  fill:#f2f2ff,stroke:#333,stroke-width:1px\n</code></pre> A. DataFrame AgentsB. Retriever AgentsC. StateGraph OrchestrationD. Human\u2011In\u2011The\u2011Loop UI <ul> <li>Analyze your pandas DataFrame to extract:<ul> <li>Variables: names, types, ranges, categorical values  </li> <li>Constraints: input-only constraints inferred from observed data patterns.</li> <li>Rules: domain rules linking features to model outcomes.</li> </ul> </li> </ul> <ul> <li>Mine unstructured sources (PDFs, docs) to extract:<ul> <li>Feature descriptions and contextual notes </li> <li>Explicit constraints and domain rules authored by experts  </li> </ul> </li> </ul> <ul> <li>Combines multiple agent outputs in a LangGraph state machine:<ol> <li>Parallel analysis &amp; retrieval of variables, constraints, rules.</li> <li>YAML generation node merges insights into a draft YAML spec.</li> <li>Human\u2011In\u2011The\u2011Loop node pauses execution and exposes the draft YAML and validator output via the UI.</li> <li>Validation node checks compliance against a Pydantic schema and runs rule-consistency checks.</li> </ol> </li> </ul> <ul> <li>Shows a Gradio interface (localhost) offering:<ol> <li>The generated YAML spec</li> <li>Validator feedback</li> <li>Text area to edit or add instructions</li> <li>Buttons: Validate, Regenerate, Finish</li> </ol> </li> </ul> <p>Validation Loop</p> <p>If schema validation or rule-consistency checks fail, control returns to the interactive UI.  Use Validate after manual fixes or Regenerate to iterate until the specification meets your requirements.</p>"},{"location":"guides/ai-for-domain-generation/#modular-implementation","title":"Modular Implementation","text":"<p>VerifIA\u2019s AI\u2011Powered Domain Generation is a modular, LLM\u2011driven workflow orchestrated via LangChain and LangGraph. </p> <p>It\u2019s organized into five layers:</p>"},{"location":"guides/ai-for-domain-generation/#31-input-layer","title":"3.1 Input Layer","text":"<ul> <li>Structured Data: CSV files or pandas DataFrames  </li> <li>Unstructured Data: PDF documents (indexed in Chroma)  </li> <li>Model Card: YAML/JSON metadata describing features and target  </li> </ul>"},{"location":"guides/ai-for-domain-generation/#32-agent-layer","title":"3.2 Agent Layer","text":"<ul> <li>DataFrame Analysis Agents: Extend LangChain\u2019s pandas agent to infer variable info, and data\u2011driven constraints/rules  </li> <li>Retriever Agents: semantically extract domain rules and descriptions from PDFs using a Chroma vector store  </li> </ul>"},{"location":"guides/ai-for-domain-generation/#33-orchestration-layer","title":"3.3 Orchestration Layer","text":"<ul> <li>StateGraph Builder:<ul> <li>Adds six parallel edges from <code>START</code> to the analyser/retriever nodes.</li> <li>Registers three core nodes:             - <code>yaml_generator</code> (draft/spec generation)             - <code>human_interaction</code> (Gradio UI hook)             - <code>yaml_validator</code> (schema &amp; rule checks)  </li> </ul> </li> <li>Checkpointing: integrates a <code>MemorySaver</code> to persist intermediate state, enabling retries and inspection.</li> </ul>"},{"location":"guides/ai-for-domain-generation/#34-humanintheloop-layer","title":"3.4 Human\u2011In\u2011The\u2011Loop Layer","text":"<ul> <li><code>human_interaction</code> node:  <ul> <li>Features a lightweight Gradio UI on <code>localhost</code>, displaying:<ol> <li>Current YAML draft  </li> <li>Validator feedback</li> <li>Editable text area for manual tweaks or instructions  </li> <li>Validate, Regenerate, Finish buttons  </li> </ol> </li> <li>Routes control back into the graph based on user action:<ul> <li>Validate \u2192 <code>yaml_validator</code> </li> <li>Regenerate \u2192 <code>yaml_generator</code> </li> <li>Finish \u2192 graph <code>END</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"guides/ai-for-domain-generation/#35-validation-export-layer","title":"3.5 Validation &amp; Export Layer","text":"<ul> <li><code>yaml_validator</code> node:<ol> <li>Parses the YAML string \u2192 \u2714/\u274c parse status  </li> <li>Enforces Pydantic schema \u2192 \u2714/\u274c schema status  </li> <li>Runs <code>RuleConsistencyVerifier</code> \u2192 \u2714/\u274c logical consistency  </li> <li>Appends all reports into <code>validator_output</code></li> </ol> </li> <li><code>domain_generator</code> node:  <ul> <li>On first pass, merges agent outputs and drafts a first YAML spec.  </li> <li>On regeneration, injects user edits and instructions to update the YAML spec.   </li> </ul> </li> <li>Export: when Finished, the user can download the final YAML spec to use it for Verification.  </li> </ul>"},{"location":"guides/ai-for-domain-generation/#iterative-humanintheloop-process","title":"Iterative Human\u2011In\u2011The\u2011Loop Process","text":"<p>AI assistance jump\u2011starts your domain spec, but human review ensures correctness:</p> <ul> <li>Logical consistency: Do the rules make sense?</li> <li>Completeness: Are all critical features and constraints captured?</li> <li>Refinement: Tweak prompts, schema settings, or your documents and re-run as needed.</li> </ul> <p>Success: Your combined domain expertise and VerifIA\u2019s AI power deliver robust, production\u2011ready specifications.</p>"},{"location":"guides/ai-for-domain-generation/#stepbystep-usage","title":"Step\u2011by\u2011Step Usage","text":""},{"location":"guides/ai-for-domain-generation/#1-install-configure","title":"1. Install &amp; Configure","text":"<pre><code>pip install verifia[genflow]\n</code></pre> <p>Set your API keys and tuning parameters:</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"                     # required\nexport VERIFIA_GPT_MODEL=\"gpt-4.1\"                 # optional, default: gpt-4o-mini\nexport VERIFIA_GPT_TEMPERATURE=\"0\"                 # default: 0 (deterministic)\nexport VERIFIA_VALIDATOR_MAX_RETRIES=\"3\"           # default: 3\n# (Optional) LangChain tracing:\nexport LANGCHAIN_API_KEY=\"lk-...\"\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\nexport LANGCHAIN_PROJECT=\"VERIFIA\"\n</code></pre>"},{"location":"guides/ai-for-domain-generation/#2-prepare-your-inputs","title":"2. Prepare Your Inputs","text":"<ul> <li>Dataset: <code>data/my_dataset.csv</code> or a pandas <code>DataFrame</code></li> <li>Documentation: PDFs/Markdown in <code>docs/</code></li> <li>Model Card: YAML file <code>model_card.yaml</code>, e.g.:</li> </ul> <pre><code>name: my_model\nversion: \"1\"\ntype: regression\nframework: sklearn\nfeature_names:\n  - feature_1\n  - feature_2\ntarget_name: target\nlocal_dirpath: ./models\n</code></pre>"},{"location":"guides/ai-for-domain-generation/#3-initialize-load-context","title":"3. Initialize &amp; Load Context","text":"<pre><code>from verifia.generation import DomainGenFlow\n\nflow = DomainGenFlow().load_ctx(\n    data_fpath=\"data/my_dataset.csv\",       # or dataframe=df\n    pdfs_dirpath=\"docs/\",                   # or db_str_content / vectordb\n    model_card_fpath=\"model_card.yaml\"      # or model_card=dict(...)\n)\n</code></pre> <p>Error Handling: Missing or invalid paths raise a <code>ValueError</code>\u2014verify your file locations before proceeding.</p>"},{"location":"guides/ai-for-domain-generation/#4-run-domain-generation-ui","title":"4. Run Domain Generation UI","text":"<pre><code># 4) spin up the UI\nflow.launch()\n</code></pre>      \ud83d\uddbc\ufe0f UI Snapshot: VerifIA Domain Spec Generator    <p> Fig. Static UI preview\u2014click image for full\u2011size view.     </p> <ul> <li>Gradio window shows your draft YAML + validation output.  </li> <li>Edit the YAML or add instructions.  </li> <li>Click Validate (loops back on errors), Regenerate (re\u2011runs generator with your notes), or Finish (after saving the YAML).</li> </ul> <pre><code>variables:\n  age:\n    description: \"Age of applicant\"\n    type: INT\n    range: [18, 65]\nconstraints:\n  positive_balance:\n    description: \"Account balance &gt; 0\"\n    formula: \"account_balance &gt; 0\"\nrules:\n  credit_risk_rule:\n    description: \"Higher debt-to-income increases risk\"\n    premises:\n      debt_income_ratio: inc\n    conclusion:\n      credit_risk: inc\n</code></pre>"},{"location":"guides/ai-for-domain-generation/#6-integrate-with-verifia-verification","title":"6. Integrate with VerifIA Verification","text":"<pre><code>from verifia.verification import RuleConsistencyVerifier\nfrom verifia.verification.results import RulesViolationResult\n\nverifier = RuleConsistencyVerifier(\"output/generated_domain.yaml\")\nresult: RulesViolationResult = (\n    verifier.verify(model_card=\"model_card.yaml\")\n            .on(data_fpath=\"data/test_data.csv\")\n            .using(\"PSO\")\n            .run(pop_size=50, max_iters=20)\n)\n</code></pre> <p>Now you can save or log your report:</p> <pre><code>result.save_as_html(\"verification_report.html\")\nresult.log_as_html(\"verifia_domain_generation_report\")\n</code></pre>"},{"location":"guides/ai-for-domain-generation/#next-steps","title":"Next Steps","text":"<ul> <li>Dive deeper into Domain Creation Guide for manual examples.</li> <li>Explore Use Case Gallery to see end\u2011to\u2011end workflows.</li> <li>Read about VerifIA's core concepts in VerifIA Concepts.</li> </ul>"},{"location":"guides/creating-a-domain/","title":"Creating a Domain YAML File","text":"<p>This guide shows you how to elaborate the domain specification that VerifIA uses to generate and validate derived inputs. For a deeper conceptual overview of \u201cdomain\u201d in VerifIA, see Concepts \u2192 Domain.</p>"},{"location":"guides/creating-a-domain/#1-why-a-domain-file","title":"1. Why a Domain File?","text":"<p>VerifIA is domain\u2011aware: it requires a\u202fpriori domain knowledge related to your application. </p> <p>Encoding that knowledge in YAML lets VerifIA:</p> <ul> <li>Derive novel inputs beyond your dataset  </li> <li>Enforce feasibility (via constraints)  </li> <li>Assert behavioral rules on model outputs  </li> </ul>"},{"location":"guides/creating-a-domain/#2-file-structure","title":"2. File Structure","text":"<p>Your domain file has three top\u2011level sections:</p> <pre><code>variables:    # define inputs &amp; outputs  \nconstraints:  # enforce feasibility on input variables only  \nrules:        # assert expected behavior  \n</code></pre>"},{"location":"guides/creating-a-domain/#21-section-variables","title":"2.1. Section: variables","text":"<p>Define raw features and model targets on their real\u2011world scale\u2014no preprocessing required.</p> Key Description <code>description</code> Human\u2011readable label for the feature or target <code>type</code> <code>INT</code>\u00a0/\u00a0<code>FLOAT</code>\u00a0/\u00a0<code>CAT</code> <code>range</code> <code>[min, max]</code> for numeric variables <code>values</code> <code>[\"v1\",\"v2\",\u2026]</code> for categorical variables (order matters if ordinal) <code>formula</code> (optional) Python expression to compute one variable from others <code>variation_limits</code> <code>[min_ratio, max_ratio]</code> percent change when deriving  e.g. <code>[0.025,0.5]</code> = 2.5%\u201350% variation <code>insignificant_variation</code> Float <code>0.0\u20131.0</code> defining:\u2022 Input noise to reveal brittleness\u2022 Output tolerance for regression errors <p>Note</p> <ul> <li>Use <code>variation_limits</code> to control drift from the seed.</li> <li>Use <code>insignificant_variation</code> to inject white\u2011noise on inputs or allow tolerable error on outputs.</li> </ul>"},{"location":"guides/creating-a-domain/#example-variables-block","title":"Example variables block","text":"<pre><code>variables:\n  age:\n    description: Customer age in years\n    type: INT\n    range: [18, 100]\n    variation_limits: [0.01, 0.10]         # 1%\u201310% change\n    insignificant_variation: 0.01         # 1% noise\n\n  income:\n    description: Annual income in USD\n    type: FLOAT\n    range: [0, 1e6]\n    formula: 12 * monthly_income          # derived from another variable\n\n  churn_probability:\n    description: Model\u2019s output probability\n    type: FLOAT\n    range: [0.0, 1.0]\n    insignificant_variation: 0.02         # 2% tolerated error\n</code></pre>"},{"location":"guides/creating-a-domain/#22-section-constraints","title":"2.2. Section: constraints","text":"<p>Define feasibility constraints over input variables only\u2014never reference the model\u2019s output or target. These formulas capture interdependencies that make certain input combinations invalid. VerifIA discards any derived point violating these constraints.</p> Key Description <code>description</code> Human\u2011readable explanation of the constraint <code>formula</code> Python expression involving only input variables"},{"location":"guides/creating-a-domain/#example-constraints-block","title":"Example constraints block","text":"<pre><code>constraints:\n  max_income_age_ratio:\n    description: Income must not exceed 100,000\u00a0\u00d7\u00a0age\n    formula: \"income &lt;= 100000 * age\"\n</code></pre> <p>Note</p> <p>Constraints must not include the target/output variable\u2014use rules for output behavior assertions.</p>"},{"location":"guides/creating-a-domain/#23-section-rules","title":"2.3. Section: rules","text":"<p>Rules assert relative expectations on model outputs when inputs change. They consist of:</p> <ol> <li>Premises: how inputs vary</li> <li>Conclusion: expected output response</li> </ol>"},{"location":"guides/creating-a-domain/#231-example-rules-block","title":"2.3.1 Example rules block","text":"<pre><code>rules:\n  high_income_reduces_churn:\n    description: \n      If income increases (age constant), churn probability should decrease\n    premises:\n      income: inc\n      age: cst\n    conclusion:\n      churn_probability: dec\n</code></pre>"},{"location":"guides/creating-a-domain/#232-premises-specifying-input-variations","title":"2.3.2 Premises: Specifying Input Variations","text":"Directive Meaning Details &amp; Examples <code>inc</code> Increase Value is strictly greater than its original seed value. <code>dec</code> Decrease Value is strictly less than its original seed value. <code>cst</code> Constant Value remains unchanged. <code>var</code> Vary May change freely within variation limits. <code>eq(\"v\")</code> Equal to specific value Must be set exactly to <code>\"v\"</code>. <code>noeq(\"v\")</code> Not equal to specific value Must not be <code>\"v\"</code>. <code>in(\"v1\",\"v2\")</code> One of a set of allowed values Must be one of <code>\"v1\"</code> or <code>\"v2\"</code>. <code>noin(\"v1\",\"v2\")</code> None of a set of values Must not be <code>\"v1\"</code> nor <code>\"v2\"</code>. <p>Note</p> <ul> <li>Combine multiple premises to constrain multi\u2011dimensional variations.</li> <li>Omitted variables default to <code>cst</code>.</li> </ul>"},{"location":"guides/creating-a-domain/#233-conclusion-expected-output-response","title":"2.3.3 Conclusion: Expected Output Response","text":"Directive Meaning When to Use <code>inc</code> Output should increase relative to seed prediction. E.g., \u201cMore feature_X \u2192 Higher risk_score.\u201d <code>dec</code> Output should decrease relative to seed prediction. E.g., \u201cHigher price \u2192 Lower demand.\u201d <code>cst</code> Output should remain unchanged. E.g., \u201cChanging log level does not affect accuracy.\u201d <code>noinc</code> Output should not increase  -&gt; may decrease or stay flat. Use when increases are disallowed but decreases acceptable. <code>nodec</code> Output should not decrease  -&gt; may increase or stay flat. Use when decreases are disallowed but increases acceptable. <p>Note</p> <p>Rule-based verification consists of comparing model predictions on derived inputs against these expectations. Violations count toward consistency metrics.</p>"},{"location":"guides/creating-a-domain/#3-full-yaml-template","title":"3. Full YAML Template","text":"<p>Use this template as <code>domain.yaml</code>\u2014replace placeholders with your actual domain definitions:</p> <pre><code>variables:\n  feature_1:\n    description: Human\u2011readable description\n    type: FLOAT\n    range: [0.0, 100.0]\n    variation_limits: [0.01, 0.20]\n    insignificant_variation: 0.02\n\n  feature_2:\n    description: Categorical feature\n    type: CAT\n    values: [\"low\",\"medium\",\"high\"]\n\n  derived_feature:\n    description: Computed feature\n    type: FLOAT\n    formula: \"2 * feature_1 + 5\"\n\n  target:\n    description: Model\u2019s output\n    type: FLOAT\n    range: [0.0, 1.0]\n    insignificant_variation: 0.05\n\nconstraints:\n  valid_income_age:\n    description: Income cannot exceed 100 \u00d7 age\n    formula: \"income &lt;= 100 * age\"\n\n  non_negative_balance:\n    description: Balance must be \u2265 0\n    formula: \"balance &gt;= 0\"\n\nrules:\n  demand_vs_price:\n    description: When price increases, demand should decrease\n    premises:\n      price: inc\n      season: cst\n    conclusion:\n      demand: dec\n\n  risk_vs_age:\n    description: Risk score should not decrease when age increases\n    premises:\n      age: inc\n    conclusion:\n      risk_score: noinc\n</code></pre>"},{"location":"reference/dataset/","title":"Dataset","text":""},{"location":"reference/dataset/#verifia.context.Dataset","title":"<code>verifia.context.Dataset</code>","text":"<p>Represents a dataset containing features and a target label. Provides functionality for sampling, and supports filtering based on domain-specific criteria.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.X","title":"<code>X</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: NumPy array containing the feature data.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.cat_feature_idxs","title":"<code>cat_feature_idxs</code>  <code>property</code>","text":"<p>Return the list of indices corresponding to categorical features.</p> <p>Returns:</p> Type Description <p>List[int]: A list of indices in self._feature_names for categorical features.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.cat_feature_names","title":"<code>cat_feature_names</code>  <code>property</code>","text":"<p>Return the list of categorical feature names.</p> <p>Returns:</p> Type Description <p>List[str]: A list of categorical feature names.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.data","title":"<code>data</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A copy of the internal DataFrame containing the dataset.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.n_samples","title":"<code>n_samples</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of samples in the dataset.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.num_feature_idxs","title":"<code>num_feature_idxs</code>  <code>property</code>","text":"<p>Return the list of indices corresponding to numeric (non-categorical) features.</p> <p>Returns:</p> Type Description <p>List[int]: A list of indices in self._feature_names for numeric features.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.num_feature_names","title":"<code>num_feature_names</code>  <code>property</code>","text":"<p>Return the list of numerical feature names in their original order.</p> <p>Returns:</p> Type Description <p>List[str]: A list of feature names that are not categorical.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.target_data","title":"<code>target_data</code>  <code>property</code>","text":"<p>Retrieve the target column from the dataset.</p> <p>Returns:</p> Type Description <code>Series</code> <p>pd.Series: A Series corresponding to the target variable specified by self._target_name.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.y","title":"<code>y</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: NumPy array containing the target (label) data.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.__init__","title":"<code>__init__(df, target_name, feature_names=None, cat_feature_names=None)</code>","text":"<p>Initializes the Dataset instance by validating the input DataFrame and inferring categorical features if not provided.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing the data.</p> required <code>target_name</code> <code>str</code> <p>Name of the target (label) column.</p> required <code>feature_names</code> <code>Optional[Iterable[str]]</code> <p>Iterable of all feature names. If None, all features names are automatically inferred from columns in the provided dataframe.</p> <code>None</code> <code>cat_feature_names</code> <code>Optional[Iterable[str]]</code> <p>Iterable of categorical feature names. If None, categorical features are automatically inferred from columns in feature_names with dtype 'object'.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the DataFrame does not contain all required columns.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.__len__","title":"<code>__len__()</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of samples in the dataset.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.feature_data","title":"<code>feature_data(enforced_data_type=False)</code>","text":"<p>Retrieve the features subset from the dataset.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing only the columns specified in self._feature_names.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.sample","title":"<code>sample(n_samples=None, prop_samples=None, replace=False, random_state=None)</code>","text":"<p>Creates a new Dataset instance by sampling rows from the current dataset.</p> <p>Either <code>n_samples</code> or <code>prop_samples</code> must be provided. If both are provided, <code>n_samples</code> takes precedence.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>Optional[int]</code> <p>The exact number of samples to extract. Must be positive.</p> <code>None</code> <code>prop_samples</code> <code>Optional[float]</code> <p>Proportion of the total samples to extract (between 0 and 1).</p> <code>None</code> <code>replace</code> <code>bool</code> <p>Whether sampling is done with replacement. Defaults to False.</p> <code>False</code> <code>random_state</code> <code>Optional[Union[int, Generator]]</code> <p>Seed or Generator for reproducible sampling.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>A new Dataset instance containing the sampled data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>n_samples</code> nor <code>prop_samples</code> is provided, if provided values are out of range,         or if sampling without replacement and <code>n_samples</code> exceeds available data.</p>"},{"location":"reference/dataset/#verifia.context.Dataset.split","title":"<code>split(primary_split_size, random_state=None)</code>","text":"<p>Split the dataset into a primary split and a secondary split.</p> <p>Parameters:</p> Name Type Description Default <code>primary_split_size</code> <code>float</code> <p>The fraction of the dataset to include in the primary split.</p> required <code>random_state</code> <code>Optional[int]</code> <p>Seed for reproducibility. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Dataset, Dataset]</code> <p>Tuple[Dataset, Dataset]: A tuple containing: - A Dataset for the primary split. - A Dataset for the secondary split.</p>"},{"location":"reference/genflow/","title":"Domain Genflow","text":""},{"location":"reference/genflow/#verifia.generation.DomainGenFlow","title":"<code>verifia.generation.DomainGenFlow</code>","text":"<p>A class to generate a domain graph flow based on provided dataset, PDFs or vector database, and a model card.</p> <p>This class encapsulates the process of loading the necessary context (data, agents, and model card) to build and run a domain graph. It allows the context to be loaded from file paths or directly from provided objects. It orchestrates the domain graph generation, human interruptions, and final domain export.</p>"},{"location":"reference/genflow/#verifia.generation.DomainGenFlow.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the DomainGenFlow instance.</p>"},{"location":"reference/genflow/#verifia.generation.DomainGenFlow.launch","title":"<code>launch(server_name=DEFAULT_HOST, server_port=DEFAULT_PORT)</code>","text":"<p>Launch the interactive Gradio UI tied to this flow.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Host/IP for the Gradio server.</p> <code>DEFAULT_HOST</code> <code>server_port</code> <code>int</code> <p>Port for the Gradio server.</p> <code>DEFAULT_PORT</code>"},{"location":"reference/genflow/#verifia.generation.DomainGenFlow.load_ctx","title":"<code>load_ctx(data_fpath=None, dataframe=None, pdfs_dirpath=None, db_str_content=None, vectordb=None, model_card_fpath=None, model_card=None)</code>","text":"<p>Load and initialize the domain context required to build the domain graph.</p> <p>At least one of 'data_fpath' or 'dataframe' must be provided, as well as one of 'pdfs_dirpath', 'vectordb', or 'db_str_content'. Similarly, either 'model_card' or 'model_card_fpath' must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>data_fpath</code> <code>Optional[Union[str, Path]]</code> <p>Path to the CSV or data file.</p> <code>None</code> <code>dataframe</code> <code>Optional[DataFrame]</code> <p>DataFrame containing the data.</p> <code>None</code> <code>pdfs_dirpath</code> <code>Optional[Union[str, Path]]</code> <p>Directory path containing PDF files.</p> <code>None</code> <code>db_str_content</code> <code>Optional[str]</code> <p>String content to build a vector database.</p> <code>None</code> <code>vectordb</code> <code>Optional[Chroma]</code> <p>Pre-initialized vector database.</p> <code>None</code> <code>model_card_fpath</code> <code>Optional[Union[str, Path]]</code> <p>Path to the model card YAML file.</p> <code>None</code> <code>model_card</code> <code>Optional[Dict[str, Any]]</code> <p>Model card as a dictionary.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DomainGenFlow</code> <code>DomainGenFlow</code> <p>The instance with the graph_context loaded.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required context arguments are missing.</p>"},{"location":"reference/genflow/#verifia.generation.DomainGenFlow.next_action","title":"<code>next_action(gen, action, yaml_str, instructions='')</code>","text":"<p>Resume the flow based on a UI action (validate/regenerate/finish).</p> <p>Parameters:</p> Name Type Description Default <code>gen</code> <code>Generator[Dict[str, Any], Any, None]</code> <p>Active generator from start or previous next_action.</p> required <code>action</code> <code>str</code> <p>Action keyword.</p> required <code>yaml_str</code> <code>str</code> <p>Current YAML shown to the user.</p> required <code>instructions</code> <code>str</code> <p>User instructions for regeneration.</p> <code>''</code> <p>Returns:</p> Type Description <code>Tuple[str, str, Generator[Dict[str, Any], Any, None]]</code> <p>Tuple of updated (yaml_text, validation_output, generator).</p>"},{"location":"reference/genflow/#verifia.generation.DomainGenFlow.start","title":"<code>start()</code>","text":"<p>Kick off the flow until first human interrupt, returning initial YAML and validation.</p> <p>Returns:</p> Name Type Description <code>init_yaml</code> <code>str</code> <p>Initial generated YAML spec.</p> <code>init_val</code> <code>str</code> <p>Initial validation output.</p> <code>gen</code> <code>Generator[Dict[str, Any], Any, None]</code> <p>Generator to drive subsequent actions.</p>"},{"location":"reference/model/","title":"Model","text":""},{"location":"reference/model/#verifia.models.build_from_model_card","title":"<code>verifia.models.build_from_model_card(model_card_input)</code>","text":"<p>Build a model instance from a model card.</p> <p>This function accepts either a file path (str) to a YAML model card or a model card directly provided as a dictionary. The model card must contain at least the following keys:</p> <pre><code>- name: The model name.\n- version: The model version.\n- framework: The machine learning framework used.\n- type: The model type.\n- feature_names: A list of feature names.\n- target_name: The target variable name.\n</code></pre> <p>Optionally, the model card may contain:</p> <pre><code>- cat_feature_names: A list of categorical feature names.\n- classification_threshold: A threshold for classification tasks.\n- description: A description of the model.\n- local_dirpath: The local directory path for the model.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model_card_input</code> <code>Union[str, Dict[str, Any]]</code> <p>Either the file path to the model card YAML file or the model card dictionary itself.</p> required <p>Returns:</p> Name Type Description <code>BaseModel</code> <code>BaseModel</code> <p>An instance of a model (a subclass of BaseModel) configured as per the model card.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified model card file does not exist (when given a file path).</p> <code>KeyError</code> <p>If any required key is missing from the model card.</p> <code>YAMLError</code> <p>If the YAML file cannot be parsed.</p> <code>ValueError</code> <p>If the framework specified in the model card is not supported.</p>"},{"location":"reference/model/#verifia.models.SKLearnModel","title":"<code>verifia.models.SKLearnModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A scikit-learn model wrapper that implements the BaseModel interface.</p> <p>This class provides methods to save, load, and perform predictions using models trained with scikit-learn.</p>"},{"location":"reference/model/#verifia.models.SKLearnModel.__init__","title":"<code>__init__(name, version, model_type, feature_names, target_name, local_dirpath, cat_feature_names=None, classification_threshold=0.5, description=None)</code>","text":"<p>Initialize the SKLearn model wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The model name.</p> required <code>version</code> <code>str</code> <p>The model version.</p> required <code>model_type</code> <code>SupportedModelTypes</code> <p>The type of the model (regression or classification).</p> required <code>feature_names</code> <code>Iterable</code> <p>Iterable of feature names.</p> required <code>target_name</code> <code>str</code> <p>The target variable name.</p> required <code>cat_feature_names</code> <code>Optional[Iterable]</code> <p>Optional iterable of categorical feature names.</p> <code>None</code> <code>classification_threshold</code> <code>Optional[float]</code> <p>Threshold for classification tasks.</p> <code>0.5</code> <code>description</code> <code>Optional[str]</code> <p>Optional model description.</p> <code>None</code>"},{"location":"reference/model/#verifia.models.SKLearnModel.load_model","title":"<code>load_model(path=None, *args, **kwargs)</code>","text":"<p>Load a scikit-learn model from the specified file path using cloudpickle.</p> <p>If the provided path is a directory, the default model file path is used.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path (or directory) from which to load the model.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments for cloudpickle.load.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments for cloudpickle.load.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>BaseModel</code> <code>BaseModel</code> <p>Self, to allow method chaining.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates any exception raised during file reading.</p>"},{"location":"reference/model/#verifia.models.SKLearnModel.predict","title":"<code>predict(data)</code>","text":"<p>Generate predictions for the given input data.</p> <p>For regression, only predictions are produced. For classification, predictions and probabilities are produced.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Name Type Description <code>ModelOutputs</code> <code>ModelOutputs</code> <p>An object containing predictions and probabilities (if applicable).</p>"},{"location":"reference/model/#verifia.models.SKLearnModel.predict_score","title":"<code>predict_score(data)</code>","text":"<p>Compute prediction scores for the given input data.</p> <p>For regression models, returns the raw predictions. For classification models, returns the probability of the positive class.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Array of prediction scores.</p>"},{"location":"reference/model/#verifia.models.SKLearnModel.save_model","title":"<code>save_model(path=None, *args, **kwargs)</code>","text":"<p>Save the scikit-learn model to the specified file path using cloudpickle.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path where the model should be saved.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments for cloudpickle.dump.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments for cloudpickle.dump.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is no model instance available to save.</p> <code>Exception</code> <p>Propagates any exception raised during file writing.</p>"},{"location":"reference/model/#verifia.models.TFModel","title":"<code>verifia.models.TFModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A TensorFlow/Keras model wrapper that implements the BaseModel interface.</p> <p>This class provides methods to save, load, and perform predictions with Keras models.</p>"},{"location":"reference/model/#verifia.models.TFModel.__init__","title":"<code>__init__(name, version, model_type, feature_names, target_name, local_dirpath, cat_feature_names=None, classification_threshold=0.5, description=None)</code>","text":"<p>Initialize the TFModel.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The model name.</p> required <code>version</code> <code>str</code> <p>The model version.</p> required <code>model_type</code> <code>SupportedModelTypes</code> <p>The type of the model (regression or classification).</p> required <code>feature_names</code> <code>Iterable</code> <p>Iterable of feature names.</p> required <code>target_name</code> <code>str</code> <p>The target variable name.</p> required <code>cat_feature_names</code> <code>Optional[Iterable]</code> <p>Optional iterable of categorical feature names.</p> <code>None</code> <code>classification_threshold</code> <code>Optional[float]</code> <p>Threshold for classification tasks.</p> <code>0.5</code> <code>description</code> <code>Optional[str]</code> <p>Optional model description.</p> <code>None</code>"},{"location":"reference/model/#verifia.models.TFModel.load_model","title":"<code>load_model(path=None, *args, **kwargs)</code>","text":"<p>Load a Keras model from the specified path.</p> <p>If the provided local_path is a directory, the default model file path is used.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path (or directory) from which to load the model.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments for load_model.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments for load_model.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>BaseModel</code> <code>BaseModel</code> <p>Self, to allow method chaining.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during loading.</p>"},{"location":"reference/model/#verifia.models.TFModel.predict","title":"<code>predict(data)</code>","text":"<p>Generate predictions for the given data.</p> <p>For classification, includes probabilities and mapped labels. For regression, includes only predictions.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Name Type Description <code>ModelOutputs</code> <code>ModelOutputs</code> <p>An object containing predictions, probabilities, and labels (if applicable).</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during data conversion or prediction.</p>"},{"location":"reference/model/#verifia.models.TFModel.predict_score","title":"<code>predict_score(data)</code>","text":"<p>Predict probabilities or regression scores for the given input data.</p> <p>Assumes a single output for the model.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Array of prediction scores.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during data conversion or prediction.</p>"},{"location":"reference/model/#verifia.models.TFModel.save_model","title":"<code>save_model(path=None, *args, **kwargs)</code>","text":"<p>Save the Keras model to the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path where the model should be saved.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments for the Keras save method.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments for the Keras save method.</p> <code>{}</code> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during saving.</p>"},{"location":"reference/model/#verifia.models.PytorchModel","title":"<code>verifia.models.PytorchModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A PyTorch model wrapper that implements the BaseModel interface.</p> <p>Provides methods to save, load, and perform inference with PyTorch models. Expects the underlying model to implement a 'build_floating_tensors' method for preprocessing.</p>"},{"location":"reference/model/#verifia.models.PytorchModel.__init__","title":"<code>__init__(name, version, model_type, feature_names, target_name, local_dirpath, cat_feature_names=None, classification_threshold=0.5, description=None)</code>","text":"<p>Initialize the PyTorch model wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The model name.</p> required <code>version</code> <code>str</code> <p>The model version.</p> required <code>model_type</code> <code>SupportedModelTypes</code> <p>Model type (classification or regression).</p> required <code>feature_names</code> <code>Iterable</code> <p>Iterable of feature names.</p> required <code>target_name</code> <code>str</code> <p>The target variable name.</p> required <code>cat_feature_names</code> <code>Optional[Iterable]</code> <p>Optional iterable of categorical feature names.</p> <code>None</code> <code>classification_threshold</code> <code>Optional[float]</code> <p>Threshold for classification tasks.</p> <code>0.5</code> <code>description</code> <code>Optional[str]</code> <p>Optional model description.</p> <code>None</code>"},{"location":"reference/model/#verifia.models.PytorchModel.load_model","title":"<code>load_model(path=None)</code>","text":"<p>Load the PyTorch model from the specified file path.</p> <p>If the provided local_path is a directory, the default model filepath is used.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path (or directory) from which to load the model.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BaseModel</code> <code>BaseModel</code> <p>Self, to allow method chaining.</p> <p>Raises:</p> Type Description <code>MissingBuildFloatingTensorsError</code> <p>If the loaded model does not implement 'build_floating_tensors'.</p> <code>Exception</code> <p>Propagates any exception raised during model loading.</p>"},{"location":"reference/model/#verifia.models.PytorchModel.predict","title":"<code>predict(data)</code>","text":"<p>Generate predictions for the input data.</p> <p>For regression, only predictions are generated. For classification, generates predictions, probabilities, and maps predictions to labels.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Name Type Description <code>ModelOutputs</code> <code>ModelOutputs</code> <p>Object containing predictions and probabilities (if applicable).</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates any exception raised during prediction.</p>"},{"location":"reference/model/#verifia.models.PytorchModel.predict_score","title":"<code>predict_score(data)</code>","text":"<p>Compute prediction scores for the given input data.</p> <p>For regression, returns raw predictions. For classification, returns probability scores or class scores as appropriate.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Array of prediction scores.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates any exception raised during prediction.</p>"},{"location":"reference/model/#verifia.models.PytorchModel.save_model","title":"<code>save_model(path=None)</code>","text":"<p>Save the PyTorch model to the specified file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path (or directory) to save the model.</p> <code>None</code>"},{"location":"reference/model/#verifia.models.XGBModel","title":"<code>verifia.models.XGBModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>XGBoost model wrapper that implements the BaseModel interface for both regression and classification tasks.</p>"},{"location":"reference/model/#verifia.models.XGBModel.__init__","title":"<code>__init__(name, version, model_type, feature_names, target_name, local_dirpath, cat_feature_names=None, classification_threshold=0.5, description=None)</code>","text":"<p>Initialize the XGBModel wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The model name.</p> required <code>version</code> <code>str</code> <p>The model version.</p> required <code>model_type</code> <code>SupportedModelTypes</code> <p>Type of the model (e.g., classification or regression).</p> required <code>feature_names</code> <code>Iterable</code> <p>Iterable of feature names.</p> required <code>target_name</code> <code>str</code> <p>The target variable name.</p> required <code>cat_feature_names</code> <code>Optional[Iterable]</code> <p>Optional iterable of categorical feature names.</p> <code>None</code> <code>classification_threshold</code> <code>Optional[float]</code> <p>Classification threshold (for classification tasks).</p> <code>0.5</code> <code>description</code> <code>Optional[str]</code> <p>Optional model description.</p> <code>None</code>"},{"location":"reference/model/#verifia.models.XGBModel.load_model","title":"<code>load_model(path=None, *args, **kwargs)</code>","text":"<p>Load an XGBoost model from the specified file path.</p> <p>If the provided path is a directory, the default model filepath is used.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path (or directory) from which to load the model.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>BaseModel</code> <code>BaseModel</code> <p>Self, to allow method chaining.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during model loading.</p>"},{"location":"reference/model/#verifia.models.XGBModel.predict","title":"<code>predict(data)</code>","text":"<p>Generate predictions for the given input data.</p> <p>For regression tasks, only predictions are produced. For classification tasks, produces predictions, probabilities, and maps predictions to labels.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Name Type Description <code>ModelOutputs</code> <code>ModelOutputs</code> <p>An object containing predictions and, for classification, probabilities.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during prediction.</p>"},{"location":"reference/model/#verifia.models.XGBModel.predict_score","title":"<code>predict_score(data)</code>","text":"<p>Compute prediction scores for the given input data.</p> <p>For regression models, returns raw predictions. For classification models, returns the probability of the positive class.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input data array (1D or 2D).</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Array of prediction scores.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during prediction.</p>"},{"location":"reference/model/#verifia.models.XGBModel.prepare_inputs","title":"<code>prepare_inputs(X)</code>","text":"<p>Prepare input data by converting the NumPy array to a DataFrame with appropriate dtypes.</p> <p>This method assumes that the model's feature types are stored in its 'feature_types' attribute, where a type value of \"c\" indicates a categorical feature.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Input feature data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Processed data with columns renamed and dtypes set.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during data processing.</p>"},{"location":"reference/model/#verifia.models.XGBModel.save_model","title":"<code>save_model(path=None, *args, **kwargs)</code>","text":"<p>Save the XGBoost model to the specified file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path where the model should be saved.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments for the XGBoost save_model method.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments for the XGBoost save_model method.</p> <code>{}</code> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates exceptions raised during model saving.</p>"},{"location":"reference/model/#verifia.models.LGBModel","title":"<code>verifia.models.LGBModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A LightGBM model wrapper that extends BaseModel for regression and classification tasks.</p> <p>This class provides methods to save, load, and make predictions using LightGBM models.</p>"},{"location":"reference/model/#verifia.models.LGBModel.__init__","title":"<code>__init__(name, version, model_type, feature_names, target_name, local_dirpath, cat_feature_names=None, classification_threshold=0.5, description=None)</code>","text":"<p>Initialize a LightGBM model wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The model name.</p> required <code>version</code> <code>str</code> <p>The model version.</p> required <code>model_type</code> <code>SupportedModelTypes</code> <p>Type of the model (classification or regression).</p> required <code>feature_names</code> <code>Iterable</code> <p>Iterable of feature names.</p> required <code>target_name</code> <code>str</code> <p>The target variable name.</p> required <code>cat_feature_names</code> <code>Optional[Iterable]</code> <p>Optional iterable of categorical feature names.</p> <code>None</code> <code>classification_threshold</code> <code>Optional[float]</code> <p>Threshold for classification tasks.</p> <code>0.5</code> <code>description</code> <code>Optional[str]</code> <p>Optional model description.</p> <code>None</code>"},{"location":"reference/model/#verifia.models.LGBModel.predict","title":"<code>predict(data)</code>","text":"<p>Generate predictions for the input data.</p> <p>For regression tasks, only predictions are produced. For classification tasks, both predictions and probabilities are produced.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input feature data as a NumPy array (1D or 2D).</p> required <p>Returns:</p> Name Type Description <code>ModelOutputs</code> <code>ModelOutputs</code> <p>An object containing predictions and probabilities (if applicable).</p>"},{"location":"reference/model/#verifia.models.LGBModel.predict_score","title":"<code>predict_score(data)</code>","text":"<p>Compute prediction scores for the input data.</p> <p>For regression, returns raw predictions. For classification, returns the probability of the positive class.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>Input feature data as a NumPy array (1D or 2D).</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: A NumPy array of prediction scores.</p>"},{"location":"reference/model/#verifia.models.LGBModel.prepare_inputs","title":"<code>prepare_inputs(X)</code>","text":"<p>Prepare and convert the input NumPy array into a Pandas DataFrame with proper dtypes.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Input feature data as a NumPy array.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with column names matching the model's features and appropriate types.</p>"},{"location":"reference/model/#verifia.models.LGBModel.save_model","title":"<code>save_model(path=None, *args, **kwargs)</code>","text":"<p>Save the LightGBM model to the specified file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path (or directory) where the model should be saved.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments for LightGBM's save_model.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments for LightGBM's save_model.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no model instance is available.</p> <code>Exception</code> <p>Propagates exceptions raised during model saving.</p>"},{"location":"reference/model/#verifia.models.CBModel","title":"<code>verifia.models.CBModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A CatBoost model wrapper that extends the BaseModel interface.</p> <p>Provides methods to save, load, and make predictions using CatBoost models. Depending on the model type (classification or regression), the appropriate CatBoost estimator is used.</p>"},{"location":"reference/model/#verifia.models.CBModel.__init__","title":"<code>__init__(name, version, model_type, feature_names, target_name, local_dirpath, cat_feature_names=None, classification_threshold=0.5, description=None)</code>","text":"<p>Initialize a CatBoost model wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The model name.</p> required <code>version</code> <code>str</code> <p>The model version.</p> required <code>model_type</code> <code>SupportedModelTypes</code> <p>Type of the model (classification/regression).</p> required <code>feature_names</code> <code>Iterable</code> <p>Iterable of feature names.</p> required <code>target_name</code> <code>str</code> <p>Target variable name.</p> required <code>cat_feature_names</code> <code>Optional[Iterable]</code> <p>Optional iterable of categorical feature names.</p> <code>None</code> <code>classification_threshold</code> <code>Optional[float]</code> <p>Threshold for classification decisions.</p> <code>0.5</code> <code>description</code> <code>Optional[str]</code> <p>Optional model description.</p> <code>None</code>"},{"location":"reference/model/#verifia.models.CBModel.load_model","title":"<code>load_model(path=None, *args, **kwargs)</code>","text":"<p>Load the CatBoost model from the specified file path.</p> <p>If the provided path is a directory, the default model file path (constructed by <code>default_model_filepath</code>) is used.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>Path (or directory) from which to load the model.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>BaseModel</code> <code>BaseModel</code> <p>Self, to allow method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model type is unsupported.</p> <code>Exception</code> <p>Propagates any exception raised by the underlying load_model method.</p>"},{"location":"reference/model/#verifia.models.CBModel.predict","title":"<code>predict(data)</code>","text":"<p>Generate predictions and, if applicable, probabilities for the given data.</p> <p>For regression, only predictions are populated. For classification, both predictions and probabilities are populated.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>The input data as a NumPy array. Can be 1D or 2D.</p> required <p>Returns:</p> Name Type Description <code>ModelOutputs</code> <code>ModelOutputs</code> <p>An instance containing predictions and probabilities (if classification).</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates any exception raised during prediction.</p>"},{"location":"reference/model/#verifia.models.CBModel.predict_score","title":"<code>predict_score(data)</code>","text":"<p>Compute prediction scores for the given data.</p> <p>For regression, the raw predictions are returned. For classification, the probability of the positive class is returned.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray</code> <p>The input data as a NumPy array. Can be 1D or 2D.</p> required <p>Returns:</p> Type Description <code>Union[NDArray, float]</code> <p>Union[npt.NDArray, float]: A NumPy array of prediction scores, or a single score if one sample is provided.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Propagates any exception raised during prediction.</p>"},{"location":"reference/model/#verifia.models.CBModel.save_model","title":"<code>save_model(path=None, *args, **kwargs)</code>","text":"<p>Save the CatBoost model to the specified file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The file path where the model should be saved.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model attribute is not set.</p> <code>Exception</code> <p>Propagates any exception raised by the underlying save_model method.</p>"},{"location":"reference/result/","title":"Rules Violation Result","text":""},{"location":"reference/result/#verifia.verification.RulesViolationResult","title":"<code>verifia.verification.RulesViolationResult</code>","text":"<p>Collects, analyzes, and displays rule violation results.</p> <p>This class accumulates original inputs, rule violations, and constraint statistics from multiple verification runs. It generates HTML reports and JSON summaries to facilitate model verification analysis.</p>"},{"location":"reference/result/#verifia.verification.RulesViolationResult.display","title":"<code>display()</code>","text":"<p>Render and display the HTML report in a Jupyter Notebook.</p> <p>This method converts the HTML representation of the report (generated by self.to_html()) to a string and uses IPython's display_html to render it. The 'raw=True' parameter ensures that the HTML is interpreted as raw HTML rather than plain text.</p>"},{"location":"reference/result/#verifia.verification.RulesViolationResult.save_as_json","title":"<code>save_as_json(json_fpath)</code>","text":"<p>Save the verification results as a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_fpath</code> <code>Union[str, PathLike]</code> <p>Destination file path for the JSON report.</p> required"},{"location":"reference/result/#verifia.verification.RulesViolationResult.log_as_json","title":"<code>log_as_json(report_name)</code>","text":"<p>Log the JSON report to the model registry via MLflow or equivalent.</p> <p>Parameters:</p> Name Type Description Default <code>report_name</code> <code>str</code> <p>The report name.</p> required"},{"location":"reference/result/#verifia.verification.RulesViolationResult.to_html","title":"<code>to_html()</code>","text":"<p>Render the full verification report as an HTML document.</p> <p>This method assembles all required CSS and JavaScript assets (Bootstrap, jQuery), applies custom styling, and constructs the report structure.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The complete HTML document serialized to a string.</p>"},{"location":"reference/result/#verifia.verification.RulesViolationResult.log_as_html","title":"<code>log_as_html(report_name)</code>","text":"<p>Log the HTML report to the model registry via MLflow or equivalent.</p> <p>Parameters:</p> Name Type Description Default <code>report_name</code> <code>str</code> <p>The report name.</p> required"},{"location":"reference/result/#verifia.verification.RulesViolationResult.save_as_html","title":"<code>save_as_html(html_fpath)</code>","text":"<p>Save the complete verification report as an HTML file.</p> <p>Parameters:</p> Name Type Description Default <code>html_fpath</code> <code>Union[str, PathLike]</code> <p>Destination path for the HTML report.</p> required"},{"location":"reference/result/#verifia.verification.RulesViolationResult.clean","title":"<code>clean()</code>","text":"<p>Delete all persisted verification artifacts for this model.</p> <p>This will remove the entire directory under the global checkpoint path corresponding to this model's full name (CHECKPOINTS_DIRPATH/). Use with caution, as this operation is irreversible. <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the target directory does not exist.</p> <code>PermissionError</code> <p>If the directory or its contents cannot be removed due to filesystem permissions.</p>"},{"location":"reference/verifier/","title":"Rule Consistency Verifier","text":""},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier","title":"<code>verifia.verification.RuleConsistencyVerifier</code>","text":"<p>Manages the verification of model rules based on a domain definition and search strategy.</p> <p>Evaluates a dataset against specified rules, collects statistics, and generates detailed reports.</p>"},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier.__init__","title":"<code>__init__(domain_cfg_dict=None, domain_cfg_fpath=None)</code>","text":"<p>Initialize the verifier using a domain configuration file. Provide either a model instance or a domain configuration file path to load the domain.</p> <p>Parameters:</p> Name Type Description Default <code>domain_cfg_dict</code> <code>Optional[Dict]</code> <p>A dictionary of a domain configuration.</p> <code>None</code> <code>domain_cfg_fpath</code> <code>Optional[PathLike]</code> <p>Path to a domain configuration YAML file.</p> <code>None</code>"},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier.calculate_dataset_statistics","title":"<code>calculate_dataset_statistics()</code>","text":"<p>Compute detailed statistics for the original dataset based on domain constraints and model predictions.</p> This method performs the following steps <ol> <li>Validates that the model and dataset have been set. If not, a ValueError is raised instructing the user to call     the appropriate setup methods (verify() for the model and on() for the dataset).</li> <li>Filters out rows containing any feature value that falls outside its allowed domain. This is done using an     internal helper function that checks each row against the domain constraints.</li> <li>Records the total number of original rows (n_orig) and the number of rows removed because they are out-of-domain (n_ood).</li> <li>Computes the model's predictive performance on the entire dataset and stores the performance metric name and score.</li> <li>Further refines the filtered dataset based on the model's predictions:<ul> <li>For regression models:<ul> <li>Retrieves the error tolerance (err_thresh) from the domain of the target variable.</li> <li>Removes rows where the absolute prediction error exceeds the tolerance.</li> <li>Records the count of in-domain rows removed due to high error (n_herr).</li> </ul> </li> <li>For classification models:<ul> <li>Removes rows where the model's predictions do not match the true target values.</li> <li>Records the count of in-domain rows removed due to misclassification (n_miscls).</li> </ul> </li> </ul> </li> </ol> <p>Returns:</p> Name Type Description <code>OriginalStatistics</code> <code>OriginalStatistics</code> <p>An object containing: - n_orig: Total number of rows in the original dataset. - n_ood: Number of rows removed because they are out-of-domain. - n_herr: For regression, number of rows removed due to prediction error exceeding the tolerance. - n_miscls: For classification, number of rows removed due to misclassification. - metric_name: The name of the performance metric used. - metric_score: The score of the performance metric. - err_thresh: For regression, the error tolerance threshold applied.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model or dataset has not been set.</p>"},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier.clean_results","title":"<code>clean_results()</code>","text":"<p>Remove all previously generated verification results.</p> <p>This will delete the directory where rule\u2010violation reports and checkpoints have been stored. You must have already run a verification (i.e., called verify()) before cleaning,  otherwise no results will be available.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no results are available (i.e., verify() has not been called).</p>"},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier.on","title":"<code>on(dataframe=None, data_fpath=None, dataset=None)</code>","text":"<p>Set the dataset to be verified.</p> <p>Provide either a Dataset, a DataFrame, or a file path to the data.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>Optional[DataFrame]</code> <p>A pandas DataFrame.</p> <code>None</code> <code>data_fpath</code> <code>Optional[PathLike]</code> <p>File path to the data.</p> <code>None</code> <code>dataset</code> <code>Optional[Dataset]</code> <p>A pre-constructed Dataset object.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RuleConsistencyVerifier</code> <code>RuleConsistencyVerifier</code> <p>Self, to allow method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If none of the Dataset, DataFrame, or file path is provided.         If the model is not set, instructs the user to call verify() first.</p>"},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier.run","title":"<code>run(pop_size, max_iters, orig_seed_ratio=None, orig_seed_size=None, persistance=True)</code>","text":"<p>Execute the verification run.</p> The method performs the following steps <ul> <li>Validates input parameters.</li> <li>Samples the original dataset.</li> <li>Filters out rows violating domain constraints.</li> <li>Loads original seed predictions.</li> <li>Iterates over rules and original inputs to search for rule violations.</li> <li>Records any inconsistent candidates.</li> <li>Persists the results if requested.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>pop_size</code> <code>int</code> <p>Population size for the search algorithm.</p> required <code>max_iters</code> <code>int</code> <p>Maximum iterations for the search.</p> required <code>orig_seed_ratio</code> <code>Optional[float]</code> <p>Ratio of original seed samples to use.</p> <code>None</code> <code>orig_seed_size</code> <code>Optional[int]</code> <p>Number of original seed samples to use.</p> <code>None</code> <code>persistance</code> <code>bool</code> <p>Whether to persist the run results. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>RulesViolationResult</code> <code>RulesViolationResult</code> <p>The final verification result.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If pop_size or max_iters are not integers, or if seed parameters have incorrect types.</p> <code>ValueError</code> <p>If pop_size or max_iters are out of valid ranges, or if neither seed parameter is provided.         Also if the model, dataset, or searcher have not been set.</p>"},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier.using","title":"<code>using(search_algo, search_params=None, search_params_fpath=None)</code>","text":"<p>Specify the search algorithm and parameters for verification.</p> <p>Parameters:</p> Name Type Description Default <code>search_algo</code> <code>str</code> <p>The identifier of the search algorithm.</p> required <code>search_params</code> <code>Optional[dict]</code> <p>A dictionary of search parameters.</p> <code>None</code> <code>search_params_fpath</code> <code>Optional[PathLike]</code> <p>Path to a configuration file for search parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RuleConsistencyVerifier</code> <code>RuleConsistencyVerifier</code> <p>Self, to allow method chaining.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If no search parameters are provided.</p>"},{"location":"reference/verifier/#verifia.verification.RuleConsistencyVerifier.verify","title":"<code>verify(model=None, model_card_fpath_or_dict=None)</code>","text":"<p>Set up the model for verification.</p> <p>Provide either a model instance or a model card file path to build the model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[BaseModel]</code> <p>An instance of a model.</p> <code>None</code> <code>model_card_fpath</code> <code>Optional[PathLike]</code> <p>Path to a model card YAML file.</p> required <p>Returns:</p> Name Type Description <code>RuleConsistencyVerifier</code> <code>RuleConsistencyVerifier</code> <p>Self, to allow method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither model nor model_card_fpath is provided.</p>"},{"location":"tutos/","title":"Tutorials","text":"<p>Welcome to the VerifIA Tutorials\u2014two hands\u2011on guides that walk you through the core components of VerifIA on simplified examples. These tutorials will help you:</p> <ul> <li>Understand the end\u2011to\u2011end workflow (data \u2192 model wrapping \u2192 domain spec \u2192 searcher selection -&gt; verification run \u2192 reporting)  </li> <li>Get comfortable with the VerifIA API before tackling complex, real\u2011world use cases  </li> <li>Experiment freely: tweak parameters, swap algorithms, inspect intermediate results  </li> </ul>"},{"location":"tutos/#tutorial-1-rulebased-dummy-regression-verification","title":"Tutorial 1: Rule\u2011Based Dummy Regression Verification","text":"<p>In this tutorial you will learn how to:</p> <ol> <li>Generate synthetic regression data with known feature\u2013target relationships  </li> <li>Train a scikit\u2011learn pipeline  </li> <li>Define domain rules in YAML  </li> <li>Wrap the model and run the <code>RuleConsistencyVerifier</code> </li> <li>Inspect and export verification results  </li> </ol> <p>\ud83d\udc49 Start Tutorial 1</p>"},{"location":"tutos/#tutorial-2-manual-vs-aipowered-domain-generation","title":"Tutorial 2: Manual vs. AI\u2011Powered Domain Generation","text":"<p>In this tutorial you will explore two approaches to building your domain configuration on the California Housing dataset:</p> <ol> <li>Manual Domain Dictionary based on data inspection and expert intuition  </li> <li>AI\u2011Powered Generation using VerifIA\u2019s <code>DomainGenFlow</code> (GPT\u2011assisted)  </li> </ol> <p>You\u2019ll then verify a wrapped model against those rules and export your results.</p> <p>\ud83d\udc49 Start Tutorial 2</p> <p>Next up: After mastering these tutorials, dive into our Use Case Gallery for full\u2011scale examples across regression and classification that demonstrate VerifIA in realistic settings.  </p>"},{"location":"tutos/tuto_1/","title":"Tutorial 1: Rule\u2011Based Dummy Regression Verification","text":"<p>Learn how to use VerifIA to verify a synthetic regression model against rule-based expectations. This tutorial covers:</p> <ul> <li>Generating synthetic data with known feature-target relationships</li> <li>Training a scikit-learn regression pipeline</li> <li>Defining domain rules in YAML</li> <li>Wrapping the model and running the <code>RuleConsistencyVerifier</code></li> <li>Inspecting and exporting verification results</li> </ul>"},{"location":"tutos/tuto_1/#1-setup-imports","title":"1. Setup &amp; Imports","text":"<p>Import standard data-science libraries and VerifIA modules.</p> <pre><code>import logging\nimport pandas as pd\nimport tempfile\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_regression\n\nfrom verifia.models import SKLearnModel, build_from_model_card\nfrom verifia.verification.verifiers import RuleConsistencyVerifier\nfrom verifia.verification.results import RulesViolationResult\n</code></pre> <p>Logging</p> <p>You can adjust the logging level to DEBUG to see detailed verifier steps:</p> <pre><code>logging.basicConfig(level=logging.INFO)\n</code></pre>"},{"location":"tutos/tuto_1/#2-generate-synthetic-data","title":"2. Generate Synthetic Data","text":"<p>Create a 3-feature regression dataset where:</p> <ul> <li><code>pos_imp_1</code> and <code>pos_imp_2</code> are positively correlated with the target</li> <li><code>zero_imp</code> is uninformative</li> </ul> <pre><code>RAND_SEED = 0\nfeature_names = [\"pos_imp_1\", \"zero_imp\", \"pos_imp_2\"]\n\ndef make_data():\n    X, y, _ = make_regression(\n        n_samples=1000,\n        n_features=3,\n        n_informative=2,\n        noise=3,\n        bias=0.1,\n        coef=True,\n        random_state=RAND_SEED\n    )\n    df = pd.DataFrame(X, columns=feature_names)\n    df[\"target\"] = y\n    return train_test_split(df, train_size=0.8, random_state=RAND_SEED)\n\ntrain_df, test_df = make_data()\n</code></pre> Note <ul> <li>We fix the random seed for reproducibility.</li> <li>Split data into 80% train / 20% test.</li> </ul>"},{"location":"tutos/tuto_1/#3-train-the-model","title":"3. Train the Model","text":"<p>Construct and fit a scikit-learn pipeline:</p> <pre><code>pipeline = make_pipeline(\n    StandardScaler(),\n    PolynomialFeatures(degree=2),\n    LinearRegression()\n)\n\npipeline.fit(train_df[feature_names], train_df[\"target\"])\npred = pipeline.predict(test_df[feature_names])\nprint(\"RMSE:\", mean_squared_error(test_df[\"target\"], pred, squared=False))\nprint(\"MAPE:\", mean_absolute_percentage_error(test_df[\"target\"], pred))\n</code></pre> Note <ul> <li>We use degree-2 polynomial features to capture nonlinear relationships.</li> <li>Metrics on the test set give baseline performance.</li> </ul>"},{"location":"tutos/tuto_1/#4-define-domain-rules","title":"4. Define Domain Rules","text":"<p>We encode our known correlations into the domain config YAML:</p> <pre><code>variables:\n  pos_imp_1:\n    type: FLOAT\n    range: [-3, 3]\n  pos_imp_2:\n    type: FLOAT\n    range: [-3, 3]\n  zero_imp:\n    type: FLOAT\n    range: [-3, 3]\n  target:\n    type: FLOAT\n    range: [-100, 100]\n    insignificant_variation: 0.05\n\nconstraints: {}\n\nrules:\n  R_inc_pure:\n    premises: { pos_imp_1: inc, pos_imp_2: inc }\n    conclusion: { target: nodec }\n  R_dec_pure:\n    premises: { pos_imp_1: dec, pos_imp_2: dec }\n    conclusion: { target: noinc }\n  R_inc_all:\n    premises: { pos_imp_1: inc, pos_imp_2: inc, zero_imp: var }\n    conclusion: { target: nodec }\n  R_dec_all:\n    premises: { pos_imp_1: dec, pos_imp_2: dec, zero_imp: var }\n    conclusion: { target: noinc }\n</code></pre>"},{"location":"tutos/tuto_1/#5-wrap-verify","title":"5. Wrap &amp; Verify","text":"<ol> <li>Temporary YAML file (for demo):</li> </ol> <p>Save the YAML to <code>domain_rules.yaml</code> or load it via a temporary file as shown below.</p> <pre><code>tmp = tempfile.NamedTemporaryFile(\"w\", delete=False, suffix=\".yaml\")\ntmp.write(yaml_string)\ntmp.close()\ndomain_fpath = tmp.name\n</code></pre> <ol> <li>Wrap model with metadata:</li> </ol> <pre><code>model_wrapper: SKLearnModel = build_from_model_card({\n    \"name\": \"synthetic_reg\",\n    \"version\": \"1\",\n    \"type\": \"regression\",\n    \"description\": \"Synthetic data regressor\",\n    \"framework\": \"sklearn\",\n    \"feature_names\": feature_names,\n    \"target_name\": \"target\",\n    \"local_dirpath\": \"../models\"\n}).wrap_model(pipeline)\n</code></pre> <ol> <li>Instantiate verifier &amp; link data:</li> </ol> <pre><code>verifier = RuleConsistencyVerifier(domain_fpath)\nverifier.verify(model_wrapper).on(test_df)\n</code></pre> <ol> <li>Run with PSO (example):</li> </ol> <pre><code>result: RulesViolationResult = (\n    verifier.using(\"PSO\")\n            .run(pop_size=100, max_iters=10, orig_seed_ratio=1.0)\n)\n</code></pre> <p>Success</p> <p>\u2705 Verification complete!   - View Report via <code>result.display()</code> </p>"},{"location":"tutos/tuto_1/#6-export-report","title":"6. Export Report","text":"<pre><code>result.save_as_html(\"synthetic_reg_report.html\")\n</code></pre> <p>Tip</p> <p>Analyze the HTML report to grasp the different provided metrics.</p> <p>Next: Tutorial #2: Manual vs. AI\u2011Powered Domain Generation</p>"},{"location":"tutos/tuto_2/","title":"Tutorial 2: Manual vs. AI\u2011Powered Domain Generation","text":"<p>Explore two methods for generating a domain configuration on the California housing dataset:</p> <ol> <li>Manual Domain Dictionary based on feature intuition.</li> <li>AI\u2011Powered Generation using VerifIA\u2019s <code>DomainGenFlow</code>.</li> </ol>"},{"location":"tutos/tuto_2/#1-setup-imports","title":"1. Setup &amp; Imports","text":"<p>Import core libraries and VerifIA modules:</p> <pre><code>import logging\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_california_housing\n\nfrom verifia.models import SKLearnModel, build_from_model_card\nfrom verifia.verification.verifiers import RuleConsistencyVerifier\nfrom verifia.verification.results import RulesViolationResult\nfrom verifia.generation import DomainGenFlow\n</code></pre> <p>Environment</p> <p>Store secrets (e.g., OpenAI key, GPT settings) in a <code>.env</code> file and call <code>load_dotenv()</code> to configure.</p>"},{"location":"tutos/tuto_2/#2-constants-data-loading","title":"2. Constants &amp; Data Loading","text":"<pre><code>RAND_SEED = 0\nMODELS_DIRPATH = \"../models\"\n\nhousing = fetch_california_housing(as_frame=True)\nhousing_df = housing.frame\nfeature_names = housing.feature_names\ntarget_name = housing.target_names[0]\n\ntrain_df, test_df = train_test_split(\n    housing_df, train_size=0.8, random_state=RAND_SEED\n)\n</code></pre> Note <ul> <li>80/20 train-test split for consistent evaluation.</li> <li>Use <code>feature_names</code> and <code>target_name</code> directly from dataset metadata.</li> </ul>"},{"location":"tutos/tuto_2/#3-train-multiple-models","title":"3. Train Multiple Models","text":"Polynomial RegressionDecision TreeRandom ForestMLP Regressor <pre><code>poly_reg = make_pipeline(\n    StandardScaler(), PolynomialFeatures(degree=2), LinearRegression()\n)\npoly_reg.fit(train_df[feature_names], train_df[target_name])\npred = poly_reg.predict(test_df[feature_names])\nprint(\"RMSE:\", mean_squared_error(test_df[target_name], pred, squared=False))\nprint(\"MAPE:\", mean_absolute_percentage_error(test_df[target_name], pred))\n</code></pre> <pre><code>tree_reg = make_pipeline(\n    StandardScaler(), DecisionTreeRegressor(random_state=RAND_SEED)\n)\ntree_reg.fit(train_df[feature_names], train_df[target_name])\npred = tree_reg.predict(test_df[feature_names])\nprint(\"RMSE:\", mean_squared_error(test_df[target_name], pred, squared=False))\nprint(\"MAPE:\", mean_absolute_percentage_error(test_df[target_name], pred))\n</code></pre> <pre><code>forest_reg = make_pipeline(\n    StandardScaler(), RandomForestRegressor(random_state=RAND_SEED)\n)\nforest_reg.fit(train_df[feature_names], train_df[target_name])\npred = forest_reg.predict(test_df[feature_names])\nprint(\"RMSE:\", mean_squared_error(test_df[target_name], pred, squared=False))\nprint(\"MAPE:\", mean_absolute_percentage_error(test_df[target_name], pred))\n</code></pre> <pre><code>mlp_reg = make_pipeline(\n    StandardScaler(), MLPRegressor(hidden_layer_sizes=(128,64,32), random_state=RAND_SEED)\n)\nmlp_reg.fit(train_df[feature_names], train_df[target_name])\npred = mlp_reg.predict(test_df[feature_names])\nprint(\"RMSE:\", mean_squared_error(test_df[target_name], pred, squared=False))\nprint(\"MAPE:\", mean_absolute_percentage_error(test_df[target_name], pred))\n</code></pre>"},{"location":"tutos/tuto_2/#4-wrap-model-with-verifia","title":"4. Wrap Model with VerifIA","text":"<pre><code>model_card = {\n    \"name\": \"CHPrice_skl_poly_regressor\",\n    \"version\": \"1\",\n    \"type\": \"regression\",\n    \"description\": \"Predict California housing prices\",\n    \"framework\": \"sklearn\",\n    \"feature_names\": feature_names,\n    \"target_name\": target_name,\n    \"local_dirpath\": MODELS_DIRPATH\n}\n\nmodel_wrapper: SKLearnModel = build_from_model_card(model_card)\n    .wrap_model(poly_reg)  # swap for tree_reg, forest_reg, mlp_reg\n</code></pre>"},{"location":"tutos/tuto_2/#5-create-domain-configuration","title":"5. Create Domain Configuration","text":""},{"location":"tutos/tuto_2/#option-a-manual-domain-dictionary","title":"Option A \u2013 Manual Domain Dictionary","text":"<p>You can manually create a simple domain dictionary. In this example, a dictionary is built where each variable is defined based on the features from the California housing dataframe. A sample constraint (e.g., a ratio between average bedrooms and rooms) and a rule (R1) are included. You can further customize and extend this dictionary with additional rules as needed.</p> <pre><code>domain_cfg_dict = {\n    \"variables\":{\n        col: {\n            \"type\": \"INT\" if (is_int := (housing_df[col] == housing_df[col].round()).all()) else \"FLOAT\",\n            \"range\": (housing_df[col].astype(int) if is_int else housing_df[col]).agg(['min', 'max']).tolist()\n        }\n        for col in housing_df.columns\n    },\n    \"constraints\":{\n        \"C1\": {\n                \"description\":\"\", \n                \"formula\": \"AveBedrms/AveRooms &gt; 0.5\"\n            }\n    },\n    \"rules\":{\n        \"R1\": {\n               \"description\": \"\",\n               \"premises\": {\"AveRooms\":\"inc\", \"AveBedrms\":\"inc\", \"HouseAge\": \"dec\"},\n               \"conclusion\": {\"MedHouseVal\":\"inc\"}\n            }\n    }\n}\ndomain_cfg_dict[\"variables\"]['MedHouseVal']['insignificant_variation'] = 0.15 # expect 15% of error as acceptable\n</code></pre> <p>Tip</p> <p>Build <code>domain_cfg_dict</code> by inspecting <code>housing_df.describe()</code> for sensible ranges.</p>"},{"location":"tutos/tuto_2/#option-b-aipowered-domain-generation","title":"Option B \u2013 AI\u2011Powered Domain Generation","text":"<p>Alternatively, you can leverage VerifIA\u2019s <code>DomainGenFlow</code> to generate a domain dictionary automatically. By providing the dataframe and a description (here, the dataset\u2019s description from <code>housing.DESCR</code>), the tool generates a domain configuration using AI. </p> <pre><code>genflow = DomainGenFlow()\ngenflow.load_ctx(\n    dataframe=housing_df,\n    db_str_content=str(housing.DESCR),\n    model_card=model_card\n)\ndomain_cfg_dict = genflow.run()\n</code></pre> <p>Note</p> <p>Customize GPT via <code>VERIFIA_GPT_NAME</code> and <code>VERIFIA_GPT_TEMPERATURE</code> environment variables.</p>"},{"location":"tutos/tuto_2/#6-run-rule-consistency-verification","title":"6. Run Rule Consistency Verification","text":"<pre><code>verifier = RuleConsistencyVerifier(domain_cfg_dict)\nverifier.verify(model_wrapper).on(test_df)\nresult: RulesViolationResult = (\n    verifier.using(\"GA\")\n            .run(pop_size=50, max_iters=10, orig_seed_size=100)\n)\n</code></pre> <ul> <li>Algorithm: choose from RS, GA, PSO, etc.</li> <li>Parameters: <code>pop_size</code> (# candidates), <code>max_iters</code> (search steps), <code>orig_seed_size</code> (seed ratio).</li> </ul> <p>Success</p> <p>\u2705 Verification complete! - View Report via <code>result.display()</code> </p>"},{"location":"tutos/tuto_2/#7-export-results-artifacts","title":"7. Export Results &amp; Artifacts","text":"<pre><code>result.save_as_html(\"CHPrice_skl_poly_report.html\")\nmodel_wrapper.save_model()\nmodel_wrapper.save_model_card(\"CHPrice_model_card.yaml\")\n</code></pre> <p>Tip</p> <p>Use meaningful filenames (e.g., <code>tree</code>, <code>forest</code>, <code>mlp</code>) to identify model variants easily.</p>"}]}